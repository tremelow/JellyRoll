
\clearemptydoublepage
\chapter{Les propriétés revisitées de la moyennisation}
\label{chap:avg}

Ce chapitre propose une nouvelle approche permettant une obtention
directe de certains résultats connus de moyennisation. Dans la
littérature les preuves de ces résultats font appel à des récurrences ou
à des propriétés avancées sur les arbres, et requièrent de construire
les applications de moyennisation, ce qui réduit les raisonnements à la
construction en question. Dans cet article, on présente rapidement le
cadre formel qui décrit ce qu'on entend par \enquote{moyennisation},
puis on prouve quelques propriétés en supposant seulement que ces
applications existent. En particulier, on s'intéresse aux propriétés
géométriques de commutation, de conservation de volume et de structure
hamiltonienne ou de Poisson. On présente aussi ce qu'il advient de la de
ces structures géométriques dans un contexte de moyennisation approchée.

% \section{Présentation d'une méthode}


% \subsection{L'équation homologique}

% Dérivation de l'équation homologique

% Distinction entre averaging standard et stroboscopique


% \subsection{Définition d'une décomposition approchée}

% Relation de récurrence et résultat sur les bornes

% Discussion autour de la méthode pour les résultats (boules imbriquées,
% estimations de Cauchy...)



% \section{Contexte d'un problème autonome}

% \begin{equation}
%     \pa_t y = \frac{1}{\eps} G(y) + K(y)
% \end{equation}
% On décompose
% \begin{equation}
%     y^\eps(t) = \Omega^\eps _{t/\eps} \circ \Psi^\eps _t 
%     \circ \big( \Omega^\eps _0 \big)^{-1}
% \end{equation}

% \subsection{Un résultat géométrique}

% $\Omega$ est un flot, et commute avec $\Psi$. 


% \subsection{Cas d'un opérateur linéaire}

% Averaging standard : crochets de Lie

% Formes normales


% \section{Aspect numérique}

% Si on ne connaît pas le défaut, il est clair qu'on peut calculer
% numériquement 
% \begin{empheq}{equation}
%     \pa_t v\rk n = F\rk n ( v\rk n ) 
% \end{empheq}
% et alors 
% \begin{empheq}{equation}
%     u^\eps(t) = \Phi\rk n _{t/\eps} \big( v\rk n (t) \big)
%     + \bigO(\eps^{n+!})
% \end{empheq}
% Mais en fait si on montre ça, on peut montrer mieux (en supposant un peu de régularité). Section basée principalement sur l'article avec Gilles. 

% \subsection{Définition d'un nouveau problème}

% Micro-macro ou pullback

% Raideur ``retardée''

% \subsection{Convergence uniforme}

% Résultat de convergence uniforme

% Présentation de schémas intégraux et composition de schémas 

\section{Introduction}
\label{section:introduction}


This paper compiles results pertaining to \textit{high-order averaging},
that is to say the problem of separating the slow and fast dynamics in a
highly-oscillatory setting. The type of problem we consider may arise in
many realistic physical models, such as molecular
dynamics~\cite{garciaarchilla.1998.long} or charged-particle dynamics under a
strong magnetic field~\cite{chartier.2020.uniformly,
frenod.2009.long,frenod.2000.long}. It may also arise in functional
spaces; two examples are the nonlinear Klein-Gordon equation in the
nonrelativistic limit regime~\cite{bao.2014.uniformly,
bao.2019.comparison, chartier.2020.new} and the oscillatory nonlinear
Schrödinger equation~\cite{chartier.2015.uniformly,
castella.2015.stroboscopic}.


Mathematically speaking, we consider problems with forced oscillations of
the form 
\begin{equation} \label{sec:intro:eq:ode_u}
  \pa_t u^\eps(t) = f_{t/\eps}\big( u^\eps(t) \big) , 
  \qquad 
  u^\eps(0) = u_0 \in X, 
  \qquad
  t \in [0, 1] 
\end{equation}
where \( X \) is a Banach space of norm \( | \cdot | \), the
non-autonomous vector field \( (\theta,u) \in \T \times X \mapsto
f_\theta(u) \) is 1-periodic w.r.t. \( \theta \) on the torus \( \T :=
\R/\Z \). As mentioned, the space \(X\) may be simply \( \R^d \), in which
case the problem is a simple ordinary differential equation in finite
dimension, or it may be a functional space, such as the space of
square-integrable function \( L^2(\R) \). 
%
Note that this type of equation can result from the \textit{filtering} of
an autonomous equation
\begin{equation} \label{sec:intro:eq:ode_auto}
  \dot v^\eps = \frac{1}{\eps} G(v^\eps) + K(v^\eps), 
  \quad 
  v^\eps(0)=v_0 \in X
\end{equation}
if $G$ generates a $1$-periodic flow $(\theta, u) \mapsto \chi_\theta(u)$.
It links to~\ref{sec:intro:eq:ode_u} using the filtered variable 
$u^\eps(t) = \chi_{-t/\eps}\big(v^\eps(t) \big)$ which
follows an equation of the form~\eqref{sec:intro:eq:ode_u} with
$f_{\theta}(u) = \left(\partial_u \chi_{-\theta}\cdot K \right) \circ
\chi_{\theta}(u)$. 

%

The approach of averaging can be summarized as the decomposition of the
solution \( u^\eps(t) \) into a \textit{near-identity, rapidly oscillating}
change of variable \(\Phi^\eps_{t/\eps} \) and the dynamics of an
\textit{average} autonomous vector field \( F^\eps \). This can be written
\begin{equation} \label{sec:intro:eq:decomp_u}
  u^\eps(t) = \Phi^\eps_{t/\eps} \circ \Psi^\eps_t \circ 
    \big( \Phi^\eps_0 \big)^{-1} (u_0), 
\end{equation}
where \( (\theta,u) \mapsto \Phi^\eps_\theta(u) \) is 1-periodic w.r.t.
\( \theta \) and \( (t,u) \mapsto \Psi^\eps_t(u) \) is the $t$-flow
associated to \( F^\eps \), i.e. for $(t,u) \in [0,1] \times X$, 
\begin{equation}
  \frac{\dd}{\dd t} \Psi^\eps_t(u) = F^\eps \big( \Psi^\eps_t(u) \big) ,
  \qquad \Psi^\eps_0 = \id . 
\end{equation}
We refer to Lochak-Meunier~\cite{lochak.1988.multiphase} and
Sanders-Verhulst-Murdock~\cite{sanders.2007.averaging} for textbooks on
these issues. Since the goal is to separate the fast periodic part in
$\theta$ and the slow drift in $t$, averaging can be seen as analogous
to the two-scale expansion $u^\eps(t) = U^\eps(t, \theta) |_{\theta =
t/\eps}$ often found in the context of high-frequency PDEs. It
is also similar to WKB expansions~\cite{wentzel.1926.eine,kramers.1926.wellenmechanik,brillouin.1926.remarques}, since in some sense $\Phi^\eps$
captures the rapid phase dynamics and $\Psi^\eps$ the slow amplitude
changes. 

In this work, we shall not discuss specific methods to compute the
periodic change of variable or the averaged vector fields, the traditional
approach dating back to~\cite{perko.1969.higher} consists in assuming the
maps are power series in~$\eps$ and injecting the ansatz $\Phi^\eps_\theta
= \id + \sum_{n \geq 1} \Phi^{[n]}_{\theta}$
in~\eqref{sec:intro:eq:decomp_u} and identifying like terms in~$\eps$.
This formal series approach has been revisited using B-series or the
Magnus expansion in~\cite{chartier.2010.higher,
chartier.2012.formal, casas.2019.continuous}.
%
Another approach is that of ``successive substitution'' dating back
to~\cite{neishtadt.1984.separation} (albeit in a slightly different
context), and more recently in~\cite{castella.2015.stroboscopic,
chartier.2020.new}. This circumvents the ansatz and yields an
\textit{exponential} error, i.e. an error bounded by $Ce^{-\mu/\eps}$
for some $C > 0$ and $\mu > 0$. Both approaches coincide formally. 
%
Our goal in this paper is to present known results under a new light,
and to offer original proofs without having to invoke any ansatz, formal
series or construction process. 

\medskip%
A particularly well-studied case is that of the autonomous problems with
linearly-generated oscillations (i.e. linear $G$), for which the problem
of averaging can often be reduced to finding some $\theta$-independent
change of variable $\big( \Phi^\eps_0 \big) ^{-1}$, or some equivalent. It
is then possible to consider the problem on this new variable
$\big(\Phi^\eps_0 \big)^{-1} (u(t))$. As such, a link can be made with
normal forms, and specifically Birkhoff's forms technique have been
considered in this context by Bambusi~\cite{bambusi.2003.birkhoff, bambusi.2005.birkhoff-lewis, bambusi.2006.birkhoff, bambusi.2008.birkhoff},
Bourgain~\cite{bourgain.1996.construction},
Colliander~\cite{colliander.2010.transfer, colliander.2012.remark} and
Grébert~\cite{bambusi.2006.birkhoff, grebert.2011.energy,
grebert.2012.resonant}, to mention only a few. We offer some insight on
this approach in Section~\ref{sec:autonomous:rmk:std_link}.
%
Note that many of these works consider the setting of multiple
non-resonant frequencies, which is akin to considering $f$ as a function
of multiple phases $\theta_1, \theta_2, \ldots$
in~\eqref{sec:intro:eq:ode_u}. This setting has also been studied with
averaging using diophantine approximations
in~\cite{chartier.2017.convergence} and with $B$-series
in~\cite{chartier.2012.higher}. 

\bigskip %
In Section~\ref{sec:presentation}, we present some general properties of
averaging, detailing the differences between standard and stroboscopic
averaging. In Section~\ref{sec:hyp}, we enounce two assumptions which
describe what we mean by exact and approximate averaging. In
Section~\ref{sec:autonomous}, we present some remarkable properties of
averaging in the autonomous case, both for exact and approximate
averaging. In Section~\ref{sec:geometry}, we restrain ourselves to
stroboscopic averaging, and present some of its geometric properties
first in the linear exact case, then in the general case of approximate
averaging.


\section{A brief presentation of averaging} \label{sec:presentation}


Differentiating~\eqref{sec:intro:eq:decomp_u} w.r.t. \( t \) generates
\begin{equation*}
  f_{t/\eps} \circ \Phi^\eps_{t/\eps} \big( v(t) \big) 
  = \frac{1}{\eps} \pa_\theta \Phi^\eps_{t/\eps} \big( v(t) \big)
  + \pa_u \Phi^\eps_{t/\eps}\big( v(t) \big) \cdot F^\eps \big( v(t) \big)
\end{equation*}
with \( v(t) = \Psi^\eps_t \circ \big( \Phi^\eps_0 \big)^{-1} (u_0) \)
the average dynamics. By separating the rapid oscillations in $t/\eps$
and the slow drift in $t$, one obtains the \textit{homological
equation}, which is for $(\theta, u) \in \T \times X$, 
\begin{equation} \label{sec:presentation:eq:homol}
  \pa_\theta \Phi^\eps_{\theta} (u)
  = \eps \left( f_{\theta} \circ \Phi^\eps_{\theta} (u) 
    - \pa_u \Phi^\eps_{\theta} (u) \, F^\eps (u) \right) .
\end{equation}
Now taking the average, it appears that the change of variable $\Phi^\eps$
alone stores the information of the averaged vector field. Indeed, for $u$
in $X$, $F^\eps(u)$ is given by
\begin{equation}
  F^\eps (u) = \Big( \pa_u \LL \Phi^\eps \RR (u) \Big)^{-1} 
        \LL f \circ \Phi \RR (u) ,
\end{equation}
where $\LL \,\cdot\, \RR$ denotes the average, defined for a periodic map
$ (\theta, u) \in \T \times X \mapsto \varphi_\theta(u)$ by
\begin{equation}
  \LL \varphi \RR (u) = \int_0^1 \varphi_\theta (u) \dd \theta .
\end{equation}
Up to a change of variable, $\Phi^\eps$ is assumed to be near identity,
i.e. 
\begin{equation}
  \Phi^\eps = \id + \bigO(\eps) .
\end{equation}
It is known that equation~\eqref{sec:presentation:eq:homol} generally has no
rigorous solution, only solutions as a formal series in $\eps$. An example
where this divergence is observed can be found
in~\cite{chartier.2010.higher}. However the series converges in the
case where $f_\theta$ is a linear and bounded operator, for $\eps$ small
enough. 

Perhaps the most straighforward approach to solve the homological equation
is a fixed point method separating the right-hand side of the equation (of
size $\eps$) and the left (of size $1$). It immediately appears that a
closure condition on $\Phi^\eps$ is needed to properly invert
$\pa_\theta$. Two choices are often considered.

\smallskip\noindent
\textit{Standard averaging:} 
%
$ \LL \Phi^\eps \RR = \id ,$ 

\noindent\hfil\parbox[t]{0.85\textwidth}{%
which circumvents the computation of an inverse, as then $F^\eps = \LL f
\circ \Phi^\eps \RR$, thereby making computations less costly. In this
case, the method shares similarities with the so-called Chapmann-Enskog
method in the context of kinetic theory
(see~\cite{chartier.2020.averaging}). As highlighted
in~\cite{chartier.2020.derivative}, in numerical contexts the $\pa_u
\Phi^\eps \cdot F^\eps$-term can be replaced by a finite-differences
approximation up to some order in $\eps$, which removes the need to
compute an exact derivative and makes automatic computations much
simpler.
%
}\hfil%

\medskip\noindent
\textit{Stroboscopic averaging:}
\( \Phi^\eps_0 = \id \),

\noindent\hfil\parbox[t]{0.85\textwidth}{%
for which the solution \( u(t) \) coincides with
the average \( \Psi^\eps_t(u_0) \) at ``stroboscopic'' times \( t \in \eps
\N \). This produces more complex computations but allows for the preservation of geometric properties, such as energy
conservation or symplectic structure. 
}\hfil%


\medskip\noindent %
We shall mainly focus on the properties of stroboscopic averaging in the
upcoming sections, but it is important to keep in mind that these
choices are conjugate. Indeed, the latter can be obtained from the
former by setting 
\begin{equation*}
  \Phi^{strob} = \Phi^{std} \circ \big( \Phi_0^{std} \big)^{-1} 
  \quad
  \text{and} 
  \quad
  \Psi^{strob} 
  = \Phi_0^{std} \circ \Psi^{std} \circ \big( \Phi_0^{std} \big)^{-1} ,
\end{equation*}
i.e. $F^{strob} = \left( \pa_u \Phi_0^{std} \cdot F^{std} \right) \circ
\big( \Phi_0^{std} \big)^{-1}$. Conversely, standard averaging can be
obtained from stroboscopic averaging with the relations
\begin{equation} \label{sec:presentation:eq:strob2std}
  \Phi^{std} = \Phi^{strob} \circ \bLL \Phi^{strob} \bRR^{-1} 
  \quad
  \text{and} 
  \quad
  \Psi^{std} 
  = \bLL\Phi^{strob}\bRR \circ \Psi^{strob} \circ 
    \bLL\Phi^{strob}\bRR^{-1} .
\end{equation}
Thus some properties of standard averaging will also be discussed. 


\section{Mathematical setting}
\label{sec:hyp}

We consider two different settings~: one of \textit{exact} averaging,
and an other of \textit{approximate} averaging. The first is on the
entire space~$X$ and corresponds to the behaviour of linear problems.
The second is on a possibly-bounded subspace~$\mathcal{K}$ and
corresponds to the behaviour of analytic problems. The results are
stronger in the first setting, but the second is more general, therefore
we treat them separately in the sequel.

\begin{assumption} \label{hyp:exist_avg_lin}
  There exists an upper bound~$\eps_0 > 0$ such that for all $u_0 \in X$
  and~$\eps \in (0, \eps_0]$, Problem~\eqref{sec:intro:eq:ode_u} is
  well-posed for $t \in [0,1]$. Furthermore for all $\eps \in (0,
  \eps_0]$, the averaging maps $(\theta, u) \in \T \times X \mapsto
  \Phi^\eps_\theta(u)$ and $u \in X \mapsto F^\eps (u)$ are well-defined
  and smooth w.r.t.~$u$. In addition,~$\pa_u F^\eps$ is bounded on~$X$
  uniformly w.r.t. $\eps$ and~$F^\eps$ is linearly bounded, which is to
  say
  \begin{equation*}
    \exists M, \kappa \geq 0,\ \forall \eps \in (0, \eps_0],\ 
    \forall (u,v) \in X, \quad
    |F^\eps(u)| \leq M + \kappa |u|
    \quad\text{and}\quad
    |\pa_u F^\eps (u)\, v| \leq \kappa |v| .
  \end{equation*}
  For all $\theta \in \T$, the inverse $u \mapsto \big(\Phi^\eps _\theta
  \big)^{-1}(u)$ and~$v \mapsto \big( \pa_u \Phi^\eps _\theta(u)
  \big)^{-1} v$ are well-defined. The same is true of the average of
  $\Phi^\eps$, i.e. by replacing $\Phi^\eps _\theta$ by $\LL \Phi^\eps
  \RR$ in the previous expressions. 
\end{assumption}
This setting corresponds to the behaviour of problems where $(\theta, u)
\mapsto f_\theta(u)$ is linear w.r.t.~$u$. It follows from this
assumption that the $t$-flow of~$F^\eps$, namely~$(t,u) \mapsto
\Psi^\eps _t(u)$ is defined for all $t \in \setR$. Note that this
assumption does not involve the closure condition on~$\Phi^\eps$.


Before discussing the other setting, if~$X$ is a \textit{real} Banach
space, let us introduce~$X_{\setC}$ the complexification of~$X$, defined
as 
\begin{equation*}
  X_{\setC} := \{ z = u + iv,\ (u,v) \in X^2 \} .
\end{equation*}
We denote $u = \Re(z) \in X$ and $v = \Im(z) \in X$ the real and
imaginary parts of~$z$ respectively. The complexified space~$X_{\C}$ is a
Banach space when endowed with the norm 
\begin{equation*}
  |z|_{X_\C} := \sup_{|\xi| = 1} |\Re(\xi z)|. 
\end{equation*}
Note that for $u \in X$, this norm $|u|_{X_\C}$ coincides with the norm
of the real space $|u|$, thus in the sequel, we write $|\cdot|$ to
denote the norm on the complexified space $X_\C$ indiscriminately.
Denote now~$\mathcal{K}$ a subspace of~$X$ on which we shall conduct our
study. Given a radius $\rho > 0$, we denote 
\begin{equation*}
  \mathcal{K}_{\rho} := \big\{
    u + \tilde{u}, \quad 
      (u,\tilde{u}) \in \mathcal{K} \times X_\C, 
      |\tilde{u}| \leq \rho
  \big\} ,
\end{equation*}
i.e.~$\mathcal{K}_\rho$ is the extension of $\mathcal{K}$ in $X_\C$ by a
radius~$\rho$. We also define the norm, given a map $\varphi$ from
$\mathcal{K}_\rho$ to some Banach space $(E, |\cdot|)$, 
\begin{equation*}
  \| \varphi \|_\rho = \sup_{u \in \mathcal{K}_\rho} |\varphi(u) |.
\end{equation*}
In particular for maps $\varphi: X \rightarrow X$, we have $E = X$, and
for their derivatives $E = \mathcal{L}(X,X)$ endowed with the operator
norm $\vertiii{\cdot}$. 

\begin{assumption} \label{hyp:exist_avg_nl} %
  There exists an upper parameter~$\eps_0$ such that
  Problem~\eqref{sec:intro:eq:ode_u} is well-posed for $t \in [0,1]$
  with an initial condition $u(0) \in \mathcal{U}_0 \subset
  \mathcal{K}$. For some radius~$R > 0$, the vector field $(\theta ,
  u) \mapsto f_\theta(u)$ and its derivative are bounded (uniformly
  w.r.t. $\theta$) on $\mathcal{K}_{3R}$. Given a rank $n \in \N$,
  for~$\eps \leq \eps_n := \eps_0 / (n+1)$, there are approximations
  $(\theta, u) \in \T \times \mathcal{K}_{3R} \mapsto \Phi\rk{n}_\theta
  (u)$ and $u \in \mathcal{K}_{3R} \mapsto F\rk n (u)$ which are
  well-defined and respect the bounds
  \begin{equation*}
    \sup_{\theta \in \T} \| \Phi\rk n_\theta - \id \| _{3R} 
      \leq \frac{\eps}{\eps_n}\, \frac R 2
    \qquad\text{and}\qquad
    \| F\rk n \|_{3R} \leq M 
  \end{equation*}
  for some $M > 0$ independent of~$\eps$. Both maps are analytic
  w.r.t.~$u$, with a radius of convergence everywhere greater than~$R$.
  In addition, the error of approximation is of size $\eps^{n+1}$, i.e.
  writing $\Psi\rk n _t$ the $t$-flow of $F\rk n$, for all $u_0 \in
  \mathcal{U}_0$ and $t \in [0,1]$, 
  \begin{equation} \label{sec:approx:def:avg_approx}
    u(t) = \Phi\rk n _{t/\eps} \circ \Psi\rk n _t \circ \big( \Phi\rk n _0
    \big)^{-1} (u_0) + \bigO(\eps^{n+1}) .
  \end{equation}
\end{assumption}

This assumption matches the behaviour generally observed with averaging
when assuming $(\theta,u) \mapsto f_\theta(u)$ analytic w.r.t. $u$,
found for instance in~\cite{castella.2015.stroboscopic}. As noted
in~\cite{chartier.2015.higher}, if such approximations exist for all~$n
\in \setN$, this is enough to ensure the historical optimal
``exponential'' error bound of~\cite{neishtadt.1984.separation}, which
can be stated as such: there exist two positive constants $C$ and $\nu$
such that for all $\eps > 0$ one can choose an integer $n$ such that for
all $t$,
\begin{equation*}
  \left| u(t) - \Phi\rk n _{t/\eps} \circ \Psi\rk n_t 
  \circ \big( \Phi\rk n _0 \big)^{-1} (u_0) \right| 
  \leq C e^{-\nu/\eps} .
\end{equation*}
This reflects the fact that the maps $\Phi^\eps$ and $F^\eps$ can only
be obtained as diverging power series in $\eps$, therefore the error is
\textit{formal}, or up to a flat function. Indeed, in order to increase
the order of the approximation, $\eps$ must get smaller and smaller,
such that an error $\bigO( \eps^\infty )$ is impossible with $\eps \neq
0$. The error of approximation is caracterised by the defect $\delta\rk
n$ defined by
\begin{equation*} 
  \delta\rk n _{\theta} 
  = \frac{1}{\eps} \pa_\theta \Phi\rk n _\theta
    - f_\theta \circ \Phi\rk n _\theta 
    + \pa_u \Phi\rk n _\theta \cdot F\rk n , 
\end{equation*}
which corresponds to the error in the homological
equation~\eqref{sec:presentation:eq:homol}. The previous assumptions
corresponds to the situation
\begin{equation} \label{sec:approx:hyp:delta}
  \sup_{\theta \in \T} \| \delta\rk n \| _{3R} = \bigO( \eps^n )
  \qquad\text{and}\qquad
  \LL \delta\rk n \RR = \bigO( \eps^{n+1} ) .
\end{equation}
%

The assumption of analyticity allows the use of \textit{Cauchy
estimates}, which admit the following wording~: given a function $u
\mapsto \varphi(u)$ which is analytic around some $u \in \mathcal{K}_R$
with a radius of convergence $\rho > 0$, then for all $0 < \delta <
\rho$, 
\begin{equation*}
  \pa_u \varphi(u) \cdot v = \frac{1}{2i\pi}
    \int_{|\xi| = \delta/|v|} \frac{\varphi(u+\xi v)}{\xi^2} \D \xi ,
\end{equation*}
where $\varphi(u + \xi v)$ is defined by the power series around $u$.
From this we deduce the so-called Cauchy estimate,
\begin{equation} \label{sec:intro:eq:cauchy}
  \big| \pa_u \varphi(u) \cdot v \big| 
  \leq \frac{|v|}{\delta} 
    \sup_{|\xi| = \delta/|v|} |\varphi(u + \xi v)| .
\end{equation}
Along with Assumption~\ref{hyp:exist_avg_nl}, this estimate is
sufficient to show that $\Phi^\eps _\theta$ (for any $\theta \in \T$)
and $\LL \Phi^\eps \RR$ are invertible for $\eps$ small enough. Indeed,
given $u \in X$ and denoting $\Phi^\eps$ any of the previously cited
maps, the function $\varphi_u(v) = u + v - \Phi^\eps(u+v)$ is a
contraction on the ball $\{ v \in X_\C;\ |v| \leq R \}$. From the
identity
\begin{equation*}
  \varphi_u(v) - \varphi_u(w)
  = \int_0^1 \Big(
    \id - \pa_u \Phi^\eps \big(u + \mu v + (1 - \mu) w \big)
  \Big) \cdot (v - w) \D\mu 
\end{equation*}
in which $(u + \mu v + (1-\mu)w)$ is in $\mathcal{K}_{2R}$, it is
possible to apply a Cauchy estimate with~$\delta = R$ to obtain
$\displaystyle \big| \varphi_u (v) - \varphi_u (w) \big| \leq
\frac{\eps}{2\eps_n} |v-w|$, from which the Banach fixed-point theorem
can be applied. Then, there exists a unique $|v^*| \leq R$ such that
$\varphi_u(v^*) = v^*$, i.e. such that $\Phi^\eps(u + v^*) = u$. We may
therefore set $\big(\Phi^\eps \big) ^{-1} (u) = u + v^* \in
\mathcal{K}_{2R}$.


\section{Commutation of flows in the autonomous case} 
\label{sec:autonomous}

In this section we restrict ourselves to the case of an autonomous
equation of the form 
\begin{align} \label{sec:autonomous:eq:pb_v}
  \dot v^\eps = \frac{1}{\eps} G(v^\eps) + K(v^\eps), 
  \quad v^\eps(0) = v_0 \in X
\end{align}
where $G$ and $K$ are smooth function from a Banach space $X$ into itself
and where $G$ generates a $1$-periodic flow $(\theta,u) \mapsto
\chi_\theta(u)$. The approach is the same as for the non-autonomous
problem, which is to say we search a solution under the form 
\begin{align}
  v^\eps(t) = \Omega^\eps_{t/\eps} \circ \Psi^\eps_t \circ (\Omega^\eps_0)^{-1} (v_0)
\end{align}
where $\theta \mapsto \Omega^\eps_\theta$ is assumed to be $1$-periodic and
$\Psi^\eps_t$ is the $t$-flow associated to the averaged vector flow
$K^\eps$. The reasons why the notation of the change of variable changed
but not that of the average flow will be made clear as this section
progresses. The homological equation is now 
\begin{equation} \label{sec:autonomous:eq:homol}
  \quad \pa_\theta \Omega^\eps_\theta(u) - G \circ \Omega^\eps_\theta(u) 
  = \eps \Big( K \circ \Omega^\eps_\theta(u) 
    - \pa_u \Omega^\eps_\theta(u) \, K^\eps(u) \Big) .
\end{equation}

It appears that the closure condition of standard averaging must be
reconsidered. Indeed, in the limit $\eps \rightarrow 0$, the change of
variable $\Omega^\eps_\theta$ approaches $\chi_{\theta+\theta_0}$ for some
initial phase $\theta_0$. Consider for instance the case $G(u) =
2\pi\begin{pmatrix} -u_2 \\ u_1 \end{pmatrix} = 2\pi Ju$, then clearly
choosing the standard closure condition $\LL \Omega^\eps \RR = \id$ cannot
hold, as $\LL \chi \RR = 0$. 
%
Rather than discarding standard averaging altogether, we may
\textit{filter} the equation, which is to say transform it into a
problem of the form~\eqref{sec:intro:eq:ode_u} (i.e. with forced
oscillations) by left-multiplying it by $\pa_u \chi_{-\theta+\theta_1}
\big(\Omega^\eps_\theta \big)$ for some arbitrary phase $\theta_1$.
Define the filtered change of variable $\Phi^\eps_{\theta, \theta_1} =
\chi_{-\theta + \theta_1} \circ \Omega^\eps_{\theta}$, it
satisfies\footnote{ %
  This homological equation can also be obtained directly by considering
  the filtered problem of form~\eqref{sec:intro:eq:ode_u} satisfied by
  $u^\eps_{\theta_1}(t) = \chi_{-t/\eps+\theta_1}(v^\eps(t))$, which is $
  \pa_t u^\eps_{\theta_1}(t) = f_{t/\eps, \theta_1} \big( u^\eps
  _{\theta_1} (t) \big). $ %
}
\begin{equation} \label{sec:autonomous:eq:filt_homol}
  \pa_\theta \Phi^\eps_{\theta, \theta_1} (u)
  = \eps\Big( f_{\theta, \theta_1} \circ \Phi^\eps_{\theta, \theta_1}(u) - \pa_u \Phi^\eps_{\theta, \theta_1}(u) \, K^\eps(u) \Big) 
\end{equation}
with $f_{\theta, \theta_1}(u) = \left(\partial_u \chi_{-\theta +
\theta_1}\cdot K \right) \circ \chi_{\theta-\theta_1}(u)$. Note that we
exploited the identity $\pa_\theta \chi_\theta = G \circ \chi_\theta =
\pa_u \chi_\theta \, G$. 
%
Take now the average on $\theta$ of~\eqref{sec:autonomous:eq:filt_homol},
\begin{equation} \label{sec:autonumous:eq:filt_homol_avg}
  0 = \eps\Big( 
    \bLL f_{\bigcdot, \theta_1}  \circ \Phi_{\bigcdot, \theta_1} \bRR (u) 
    - \pa_u \bLL \Phi_{\bigcdot, \theta_1} \bRR (u) \, K^\eps(u) 
  \Big) . 
\end{equation}
The standard choice of closure condition is therefore $\LL
\Phi_{\bigcdot, \theta_1} \RR = \id$, i.e. $\Omega^\eps_\theta$ close to
$\chi_{\theta - \theta_1}$. Remember however that the phase shift
$\theta_1$ is arbitrary, therefore there are infinitely many standard
closure conditions, the canonical one being $\LL \chi_{-\theta} \circ
\Omega^\eps_\theta \RR = \id$. 


\subsection{The case of exact averaging}

Assuming that $\Omega^\eps_\theta$ is close to $\chi_{\theta +
\theta_0}$, all filtered changes of variable satisfy
\begin{equation*}
  \Phi^\eps_{\theta, \theta_1} 
  = \chi_{-\theta + \theta_1} 
    \circ \big( \chi_{\theta + \theta_0} + \bigO( \eps ) \big)
  = \chi_{\theta_1 + \theta_0} + \bigO(\eps) .
\end{equation*}
Consider now that the averaging maps of the filtered homological
equation~\eqref{sec:autonomous:eq:filt_homol}, namely~$\Phi^\eps
_{\theta, \theta_1}$ and~$K^\eps$, satisfy
Assumption~\ref{hyp:exist_avg_lin} up to replacing~$\id$
by~$\chi_{\theta_1 + \theta_0}$, and assume furthermore that the
operator $\pa_u \chi_\theta(u)$ is uniformly bounded for all~$(\theta,
u) \in \T \times X$. Then $\pa_u \LL \Phi^\eps _{\theta, \theta_1} \RR$
is invertible for~$\eps$ small enough, and we may write
from~\eqref{sec:autonumous:eq:filt_homol_avg}, 
\begin{equation} \label{sec:autonomous:eq:filt_avg_map}
  K^\eps(u) = 
  \Big( \pa_u \bLL \chi_{-\theta+\theta_1} 
    \circ \Omega^\eps _\theta \bRR (u) \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta+\theta_1} \cdot K) 
    \circ \Omega^\eps _\theta \BRR (u) .
\end{equation}
Defining an operator which extracts the average behaviour 
\begin{equation} \label{sec:autonomous:def:avg_op}
  \mathcal{A}^{\theta_1}[\varphi] := 
  \big( \pa_u \bLL \chi_{-\theta+\theta_1} 
    \circ \varphi_\theta \bRR \big) ^{-1} 
  \bLL (\pa_u \chi_{-\theta+\theta_1} \cdot K) 
    \circ \varphi _\theta \bRR , 
\end{equation}
the change of variable $\Omega^\eps$ may be
defined as the unique solution to the homological equation 
\begin{equation} \label{sec:autonomous:eq:only_Omega_homol}
  \pa_\theta \Omega^\eps _\theta - G \circ \Omega^\eps _\theta
  = \eps \big( K \circ \Omega^\eps _\theta 
    - \pa_u \Omega^\eps _\theta \cdot \mathcal{A}^{\theta_1}[\Omega^\eps] 
  \big) 
\end{equation}
that is 1-periodic and satisfies some closure condition. Note that the
above equation is considered with fixed $\theta_1$, but modifying this
phase has no impact on the definition of $\Omega^\eps$. Using the
original homological equation~\eqref{sec:autonomous:eq:homol}, this may
be restated as
\begin{equation*}
  \forall \theta_1 \in \T, \qquad
  K^\eps = \mathcal{A}^{\theta_1}[\Omega^\eps] 
  = \mathcal{A}^{0}[\Omega^\eps] . 
\end{equation*}
Thanks to this invariance, a group relation may be found in the case of
stroboscopic averaging, summarized by the following proposition.

%

\begin{proposition} \label{sec:autonomous:prop:phigroup} %
  If the averaging maps of the filtered problem, namely the change of
  variable $(\theta,u) \mapsto \chi_{-\theta} \circ \Omega^\eps
  _\theta(u)$ and $u \mapsto K^\eps(u)$ satisfy
  Assumption~\ref{hyp:exist_avg_lin}, then when considering stroboscopic
  averaging, for all $\theta$ and all $\theta_0$, the following group
  relation is satisfied 
  $$
    \Omega^\eps_{\theta} \circ \Omega^\eps_{\theta_0} 
    = \Omega^\eps_{\theta + \theta_0}.
  $$
  Equivalently, there exists a vector field $G^\eps$ such that 
  $$
  \forall \theta, \ \forall u, \qquad 
  \frac{\dd}{\dd \theta} \Omega^\eps_\theta(u) 
  = G^\eps \circ \Omega^\eps_\theta(u).
  $$
\end{proposition}
\begin{proof}
Consider the $\theta$-map  
$$
\widetilde \Omega^\eps_{\theta} 
= \Omega^\eps_{\theta+\theta_0} \circ (\Omega^\eps_{\theta_0})^{-1}.
$$
Writing equation~\eqref{sec:autonomous:eq:homol} with $\theta$ replaced by
$\theta+\theta_0$ and $(\Omega^\eps_{\theta_0})^{-1}(u)$ in lieu of $u$,
we obtain with all maps evaluated in $u$, 
\begin{equation} \label{sec:autonomous:eq:tilde_homol}
  \partial_\theta \widetilde\Omega^\eps_{\theta}
  - G \circ \widetilde \Omega^\eps_{\theta}
  = \eps\left( K \circ \widetilde \Omega^\eps_{\theta}
    - \partial_u \widetilde \Omega^\eps_{\theta} \cdot 
      \left(\partial_u (\Omega^\eps_{\theta_0})^{-1} \right)^{-1} \cdot 
      K^\eps \circ (\Omega^\eps_{\theta_0})^{-1} 
  \right) .
\end{equation}
The new averaged vector field $\widetilde{K}^\eps = \left(\partial_u
(\Omega^\eps_{\theta_0})^{-1}\right)^{-1} \cdot K^\eps \circ
(\Omega^\eps_{\theta_0})^{-1} $ can be written 
\begin{align*}
  \widetilde{K}^\eps = &
  \Big( \Big( \pa_u \bLL \chi_{-\theta+\theta_0} 
      \circ \Omega^\eps _\theta \bRR \Big) 
    \circ \big( \Omega^\eps_{\theta_0} \big)^{-1} \cdot
    \pa_u (\Omega^\eps_{\theta_0})^{-1} \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta+\theta_0} \cdot K) 
    \circ \Omega^\eps _\theta  \circ (\Omega^\eps_{\theta_0})^{-1} \BRR ,
\end{align*}
exploiting~\eqref{sec:autonomous:eq:filt_avg_map} with $\theta_1 =
\theta_0$. The derivatives can be concatenated into $\pa_u \bLL
\chi_{-\theta + \theta_0} \circ \Omega^\eps _\theta \circ (\Omega^\eps
_{\theta_0})^{-1} \bRR$. Exploiting then the phase invariance of the
average, i.e. $\LL \varphi_{\theta} \RR = \LL \varphi_{\theta + \theta_0}
\RR$, the identity becomes 
\begin{equation*}
  \widetilde{K}^\eps =
  \Big( \pa_u \bLL \chi_{-\theta} 
    \circ \widetilde\Omega^\eps _\theta \bRR \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta} \cdot K) 
    \circ \widetilde\Omega^\eps _\theta \BRR 
  = \mathcal{A}^{0}[\widetilde{\Omega}^\eps] .
\end{equation*}
Injecting this into~\eqref{sec:autonomous:eq:tilde_homol}, we find that
$\widetilde{\Omega}^\eps$ is a 1-periodic map which satisfies an equation
of the form~\eqref{sec:autonomous:eq:only_Omega_homol}. As we only
consider stroboscopic averaging, $\widetilde{\Omega}^\eps$ also satisfies
the same closure condition as $\Omega^\eps$, which is to say
$\widetilde\Omega^\eps _0 = \Omega^\eps _0 = \id$. Therefore, the two maps
coincide and the proof is complete. 

\end{proof}
%
\begin{proposition} \label{sec:autonomous:prop:commut} If the averaging
  maps of the filtered problem, namely the change of variable
  $(\theta,u) \mapsto \chi_{-\theta} \circ \Omega^\eps _\theta(u)$ and
  $u \mapsto K^\eps(u)$ satisfy Assumption~\ref{hyp:exist_avg_lin}, then
  when considering stroboscopic averaging, the flows $\theta \mapsto
  \Omega^\eps_\theta$ and $t \mapsto \Psi^\eps_t$ commute with each
  other, i.e.
  $$
  \forall \theta, \quad \forall t, \qquad \Omega^\eps_\theta \circ \Psi^\eps_{t} = \Psi^\eps_{t} \circ \Omega^\eps_\theta.
  $$
  Equivalently, the vector fields $G^\eps$ and $K^\eps$ commute with each
  other, i.e.
  $$
  [G^\eps,K^\eps]=0
  $$
  where $[\cdot,\cdot]$ is the usual Lie-bracket.
\end{proposition}
\begin{proof}
  The group law for $t \mapsto \Omega^\eps_{t/\eps} \circ \Psi^\eps_{t}$
  (recall that equation (\ref{sec:autonomous:eq:pb_v}) is autonomous) gives for all $s$
  and $t$
  \begin{align} \label{eq:groupphipsi}
    \left(\Omega^\eps_{s/\eps} \circ \Psi^\eps_{s} \right) \circ \left(\Omega^\eps_{t/\eps} \circ \Psi^\eps_{t} \right) = \Omega^\eps_{(s+t)/\eps} \circ \Psi^\eps_{s+t}.
  \end{align}
  The $t$-flow $\Psi^\eps_t$ satisfies a group-law by construction and
  owing to Proposition \ref{sec:autonomous:prop:phigroup}, this is also
  the case for $\Omega^\eps_\tau$. Hence, we can compose equation
  (\ref{eq:groupphipsi}) from the left by $\Omega^\eps_{-s/\eps}$ and from
  the right by $\Psi^\eps_{-t}$ and obtain 
  $$
  \Psi^\eps_{s}  \circ \Omega^\eps_{t/\eps} = \Omega^\eps_{t/\eps} \circ \Psi^\eps_{s}.
  $$
  The commutation of the vector fields then follows in a standard way. 
\end{proof}

Note that this result can also be obtained from the proof of
Proposition~\ref{sec:autonomous:prop:phigroup}, since there we find 
\begin{equation*}
  K^\eps = \widetilde{K}^\eps = \left(\partial_u
    (\Omega^\eps_{\theta_0})^{-1}\right)^{-1} \cdot K^\eps \circ
    (\Omega^\eps_{\theta_0})^{-1} ,
\end{equation*}
i.e. $K^\eps$ is invariant when conjugated by $\Omega^\eps_{\theta_0}$.


\begin{remark} \label{sec:autonomous:rmk:std_link} If $G$ is linear, then
  differentiating $\Phi^\eps _{\theta, \theta_0}$ w.r.t. $\theta$ and
  taking the average generates
  \begin{equation*}
    G^\eps 
    = \BLL \pa_u \Phi^\eps_{\theta, \theta_0} \BRR^{-1} G \, 
      \bLL \Phi^\eps _{\theta, \theta_0} \bRR 
    = \big( \pa_u \Omega_0^{std} \cdot G \big) 
      \circ \big( \Omega_0^{std} \big)^{-1}
  \end{equation*}
  if $\Omega^{std}$ is such that $\LL e^{-(\theta-\theta_0) G}
  \Omega^{std} \RR = \id$ owing to~\eqref{sec:presentation:eq:strob2std}.
  Furthermore the average vector field $K^{std}$ commutes with $G$, thanks
  to the identity
  \begin{equation*}
    [G,K^{std}] 
    = \left[ \mathbb S (G^\eps) , \mathbb S (K^\eps) \right]
    = \mathbb S \big( [G^\eps , K^\eps] \big)
    = 0
  \end{equation*}
  with $\mathbb S (F) = \big( \pa_u \Phi_0^{std} \cdot F \big) \circ
  \big( \Phi_0^{std} \big)^{-1}$. In other words, the change of variable
  $\big( \Omega^{std}_0 \big)^{-1}$ transforms the perturbed vector
  field $G + \eps K$ into $G + \eps K^{std}$, where $G$ and $K^{std}$
  commute. This corresponds to the approach of normal forms as presented
  in~\cite[Chap.~IX]{sanders.2007.averaging}.
\end{remark}



\subsection{The case of approximations}

Consider the autonomous problem~\eqref{sec:autonomous:eq:pb_v} of
Section~\ref{sec:autonomous}, 
\begin{equation*}
  \dot v^\eps = \frac{1}{\eps}G(v^\eps) + K(v^\eps),
  \qquad
  v^\eps(0) = v_0 .
\end{equation*}
The flow of $G$, denoted $(\theta,u) \mapsto \chi_\theta(u)$, is assumed
1-periodic w.r.t. $\theta$, and we assume that for every radius $\rho$,
the set $\mathcal{K}_\rho$ is invariant by the flow of $G$. Performing
averaging on this problem is equivalent to performing it on the filtered
problem 
\begin{equation*}
  \dot u^\eps(t) = \big( \pa_u \chi_{-t/\eps} \cdot K \big) 
    \circ \chi_{t/\eps} (u^\eps(t)),
  \qquad
  u^\eps(0) = v_0 .
\end{equation*}
The unfiltered variable is obtained as $v^\eps(t) =
\chi_{t/\eps}(u^\eps(t) )$. Given an approximation $v^\eps(t) = \Omega\rk
n _{t/\eps} \circ \Psi\rk n _t \circ \big( \Omega\rk n _0 \big)^{-1} +
\bigO(\eps^{n+1} )$, an approximation on~$u^\eps$ of the
form~\eqref{sec:approx:def:avg_approx} is obtained by setting $\Phi\rk n
_\theta = \chi_{-\theta} \circ \Omega\rk n _\theta$. Conversely, it is
also possible to obtain $\Omega\rk n$ from working on the filtered
problem, and in the case where $u \mapsto G(u)$ is non-linear, this latter
approach is generally more straightforward. The defect associated to 
averaging on the autonomous problem is 
\begin{equation} \label{sec:approx:def:eta}
  \eta\rk{n}_{\theta} 
  := \frac{1}{\eps} \left( \pa_\theta \Omega\rk n _\theta 
  - G \circ \Omega\rk n _\theta \right) 
  - K \circ \Omega\rk n _\theta + \pa_u \Omega\rk n _\theta K\rk n 
\end{equation}
and the link is made with the filtered averaging with the formula 
\begin{equation*}
  \eta\rk n _\theta = \pa_u \chi _\theta \big( \Phi\rk n _\theta \big)
  \cdot \delta\rk n _\theta .
\end{equation*}



\begin{proposition}[Adaptation of
Propositions~\ref{sec:autonomous:prop:phigroup} 
and~\ref{sec:autonomous:prop:commut}] \label{sec:approx:thm:commut} \hspace*{1em} 
\\
  Given averaging maps $\Phi\rk n$ and $K\rk n$ which satisfy
  Assumption~\ref{hyp:exist_avg_nl} (with $F\rk n$ replaced by $K\rk n$)
  and such that the associated defect $\delta\rk n$
  satisfies~\eqref{sec:approx:hyp:delta}, define the change of variable
  $(\theta, u) \mapsto \Omega\rk n _\theta(u) = \chi _{-\theta} \circ
  \Phi\rk n _\theta(u)$ for autonomous averaging. With this definition,
  $\Omega\rk n _\theta$ is the $\theta$-flow of a vector field $G\rk n$
  defined on $\mathcal{K}_R$ up to $\bigO(\eps^{n+2})$. Furthermore, $G\rk
  n$ and $K\rk n$ commute up to $\bigO(\eps^{n+2})$ on $\mathcal{K}_{R}$. 
\end{proposition}

\begin{proof}
The first step of the proof is to show 
\begin{equation*}
  K\rk n = \mathcal{A}^{\theta_1}[ \Omega\rk n ] + \bigO( \eps^{n+1} )
\end{equation*}
for all phases $\theta_1 \in \T$, with $\mathcal{A}^{\theta_1}$ the
operator defined in~\eqref{sec:autonomous:def:avg_op}. This result stems
from the identity on $\widetilde{\Phi}\rk n _\theta = \chi_{-\theta -
\theta_1} \circ \Omega\rk n _\theta$, 
\begin{equation*}
  \pa_\theta \widetilde{\Phi}\rk n _\theta 
  = \eps \big( f_{\theta+\theta_1} \circ \widetilde{\Phi}\rk n _\theta
    - \pa_u \widetilde{\Phi}\rk n _\theta \cdot K\rk n 
  \big)
  - \eps \pa_u \chi_{-\theta - \theta_1}(\Omega\rk n _\theta) 
    \cdot \eta\rk n _\theta .
\end{equation*}
Before taking the average, compute
\begin{align*}
  \pa_u \chi_{-\theta - \theta_1}(\Omega\rk n _\theta) 
    \cdot \eta\rk n _\theta = &\ 
  \pa_u \chi_{-\theta-\theta_1} \big( \chi_\theta \Phi\rk n _\theta \big)
  \pa_u \chi_\theta (\Phi\rk n _\theta) \delta\rk n _\theta
  \\ = &\ 
  \pa_u ( \chi_{-\theta-\theta_1} \circ \chi_\theta 
    \circ \Phi\rk n _\theta)
  \big( \pa_u \Phi\rk n _\theta \big)^{-1} \delta\rk n _\theta
  \\ = &\ 
  \pa_u \chi_{-\theta_1} (\Phi\rk n _\theta) \delta\rk n _\theta
\end{align*}
Hence this term can be written as $\pa_u \chi_{-\theta_1} \big( \id +
\bigO(\eps) \big) \delta\rk n _\theta$, and its average is of size
$\bigO( \eps^{n+1} )$ thanks to the assumption on $\delta\rk n$. Taking
the average of the previous identity, we finally obtain 
\begin{equation*}
  K\rk n = \mathcal{A}^{\theta_1} [\Omega\rk n] + \bigO( \eps^{n+1} ) .
\end{equation*}


We then proceed in the same manner as for the proof of
Proposition~\ref{sec:autonomous:prop:phigroup}. For some phase $\theta_0
\in \T$, consider the map $\widetilde{\Omega}\rk n _\theta = \Omega\rk n
_{\theta + \theta_0} \circ \big( \Omega\rk n _{\theta_0} \big) ^{-1}$
defined on $\mathcal{K}_R$. By definition of the defect, this new map
satisfies the equation, 
\begin{equation*} 
  \partial_\theta \widetilde\Omega\rk n _{\theta}
  - G \circ \widetilde \Omega\rk n _{\theta}
  = \eps\left( K \circ \widetilde \Omega\rk n _{\theta}
    - \partial_u \widetilde \Omega\rk n _{\theta} \cdot 
    \widetilde{K}\rk n
  \right) 
  - \eps \widetilde{\eta}\rk n _\theta  .
\end{equation*}
with $\widetilde{K}\rk n = \big(\partial_u (\Omega\rk n _{\theta_0})^{-1}
\big)^{-1} \cdot K\rk n  \circ (\Omega\rk n _{\theta_0})^{-1}$ and $
\widetilde{\eta}\rk n _\theta = \eta\rk n _{\theta + \theta_0} \circ
(\Omega\rk n _{\theta_0} ) ^{-1}$. From~\eqref{sec:approx:def:eta}, it
appears in particular that $K\rk n = \mathcal{A}^{\theta_0}[\Omega\rk n] +
\bigO(\eps^{n+1} \big)$. Injected into $\widetilde{K}\rk n$, this
generates 
\begin{equation*}
  \widetilde{K}\rk n = 
  \Big( \pa_u \bLL \chi_{-\theta} 
    \circ \widetilde\Omega^\eps _\theta \bRR \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta} \cdot K) 
    \circ \widetilde\Omega^\eps _\theta \BRR + \bigO( \eps^{n+1} ) 
  = \mathcal{A}^{0}[\widetilde{\Omega}^\eps] + \bigO( \eps^{n+1} ) . 
\end{equation*}
Hence $\Omega\rk n$ and $\widetilde{\Omega}\rk n$ satisfy the same
equation up to a modification of the defect while still
respecting~\eqref{sec:approx:hyp:delta}. In other words, we can replace
$\Omega\rk n$ by $\widetilde{\Omega}\rk n$ in the following equation 
\begin{equation*}
  \partial_\theta \Omega\rk n _{\theta}
  - G \circ  \Omega\rk n _{\theta}
  = \eps\left( K \circ  \Omega\rk n _{\theta}
    - \partial_u  \Omega\rk n _{\theta} \cdot 
    \mathcal{A}^0[\Omega\rk n]
  \right) + \bigO( \eps^{n+1}) 
\end{equation*}
without impacting the result. Since these two maps satisfy the same
closure condition $\Omega\rk n _0 = \id + \bigO( \eps^{n+1} )$, they
differ by only $\bigO( \eps^{n+1})$ at any phase $\theta \in \T$. We can
finally define 
\begin{equation*}
  G\rk n = \pa_\theta \Omega\rk n _\theta \big|_{\theta = 0} .
\end{equation*}
The second part of the theorem stems from the identity $K\rk n =
\widetilde{K}\rk n + \bigO( \eps^{n+1} )$ which becomes 
\begin{equation*}
  K\rk n \circ \Omega\rk n _{\theta_0} 
  = \pa_u \Omega\rk n _{\theta_0} \cdot K\rk n + \bigO ( \eps^{n+1} ) . 
\end{equation*}
\end{proof}

Note that defined as such, the exact flow of $G\rk n$ may not be
1-periodic depending on its definition. Think for instance of the
one-dimensional example $G\rk n = 2i\pi(1-\eps) \sum_{k = 0}^{n} \eps^k =
2i\pi( 1 - \eps^{n+1})$, which does not generate a $1$-periodic flow
while its limit $(n \rightarrow \infty)$ does. 



\section{Stroboscopic averaging and geometry}
\label{sec:geometry}

In this section, we start by defining some geometric properties on
vector fields (namely, being divergence-free, Hamiltonian or
$B$-Poisson, or having an invariant). We then consider a problem with
forced oscillations, i.e. of the form~\eqref{sec:intro:eq:ode_u}, and
show that if for all~$\theta \in \T$, $u \mapsto f_\theta(u)$ satisfies
one of the geometric properties previously presented, then the averaged
vector field~$F^\eps$ satisfies the same property; first in an exact
setting, then when considering approximations.

This result extends to autonomous problems of the
form~\eqref{sec:intro:eq:ode_auto}. Indeed, if both~$G$ and~$K$ satisfy
a geometric property, then this property is also satisfied by~$f_\theta$
for all $\theta \in \T$ in the associated filtered problem, since by
definition,
\begin{equation*}
  f_\theta(u) = \big( \pa_u \chi_{\theta}(u) \big)^{-1} 
    \cdot K \circ \chi_{\theta}(u) .
\end{equation*}
In other words, $f_\theta$ is obtained by conjugating $K$ with
$\chi_\theta$, with~$K$ in a Lie algebra and~$\chi_\theta$ in the
associated Lie group. The algebra being stable by
conjugation,~$f_\theta$ satisfies the same geometric property. 
%
Since the averaged vector field of the autonomous
case~\eqref{sec:autonomous:eq:pb_v} coincides with the averaged vector
field of the filtered case (as seen in Section~\ref{sec:autonomous}),
there is no need to distinguish the autonomous case from the case with
forced oscillations.


\subsection{Definitions of geometric properties}
\label{sec:geom:subsec:def}


\begin{definition}
  A vector field function $f:\R^d \mapsto \R^d$ is said to be
  divergence free 
  \begin{align*}
    \forall u \in \R^d, \quad \sum_{i=1}^d \partial_i f_i(u) = \Tr(\partial_u f)=0.
  \end{align*}
  A smooth function $(\tau,u) \in \R \times \R^d \mapsto  S_\tau(u) \in
  \R^d$ is said to be volume-preserving iff
  \begin{align*}
    \forall (\tau, u) \in \R \times \R^d, 
    \quad \det\left (\partial_u S_\tau(u)\right)=1.
  \end{align*}
\end{definition}


\begin{remark}
  By differentiation of the determinant, it is straightforward that the
  $\tau$-flow of a divergence-free vector field is volume preserving. The
  converse is true as well. 
\end{remark}


\begin{definition}
  A smooth functional $I: X \rightarrow \setR$ is said to be an
  invariant of a vector field function $f: X \rightarrow X$ iff
  \begin{equation*}
    \forall u \in X, \quad \pa_u I(u) f(u) = 0 .
  \end{equation*}
  A smooth map $(\tau, u) \in \setR \times X \mapsto S_\tau(u)$ is said
  to preserve the functional~$I$ iff
  \begin{equation*}
    \forall (\tau, u) \in \setR \times X, \qquad
    I(u) = I \circ S_\tau (u) .
  \end{equation*}
\end{definition}

\begin{remark}
  It follows from a straightforward $\tau$-differentiation of $I \circ
  S_{\tau}$ that a vector field $f$ admits an invariant if and only if
  its $\tau$-flow $S_\tau$ preserves that invariant.  
\end{remark}


\begin{definition}
  Define the matrix $J \in {\cal M}(\R^{2d})$ as the block matrix
  $$
  J = \left(
  \begin{array}{cc}
    0 & I_n \\
    -I_n & 0
  \end{array}
  \right).
  $$
  A vector field function $f:\R^{2d} \mapsto \R^{2d}$ is said to be
  canonically  Hamiltonian if there exists a scalar smooth function
  $H:\R^{2d} \mapsto \R$ such that 
  \begin{align*}
    \forall u \in \R^{2d}, \quad f(u) = J^{-1} \nabla_u H(u).
  \end{align*}
  A smooth map $(\tau,u) \in \R \times \R^{2d} \mapsto  S_\tau(u) \in
  \R^{2d}$ is said to be symplectic iff
  \begin{align} \label{def:symplectif} %
    \forall (\tau, u) \in \R \times \R^{2d}, \quad 
    \left(\partial_u S_\tau(u)\right)^T J \left(\partial_u S_\tau(u)\right) = J,
  \end{align}
  or equivalently
  \begin{align} %
    \forall (\tau, u) \in \R \times \R^{2d}, \quad 
    \left(\partial_u S_\tau(u)\right) J^{-1} \left(\partial_u S_\tau(u)\right)^T = J^{-1} .
  \end{align}
\end{definition}


\begin{remark}
  It is known that the $\tau$-flow of a canonically Hamiltonian system
  is symplectic and that the converse is also true on connected sets.
  This is proved by differentiation and use of the integrability Lemma,
  which asserts that, on a connected set, a vector function derives from
  a gradient iff its jacobian is symmetric.
\end{remark}


\begin{definition}
  A matrix $B(u) \in {\cal M}(\R^{d})$ is said to be a Poisson matrix if
  it is skew-symmetric and satisfies the Jacobi relation
  $$
  \forall i,j,k \in \{1,\ldots,n\}, \quad \sum_{l=1}^d (\partial_l b_{ij}) b_{lk} +(\partial_l b_{jk}) b_{li}+(\partial_l b_{ki}) b_{lj} = 0. 
  $$
  A vector field function $f:\R^{d} \mapsto \R^{d}$ is said to be Poisson
  if there exists a scalar smooth function $H:\R^{d} \mapsto \R$ and a
  Poisson matrix $B(u)$ such that 
  \begin{align*}
    \forall u \in \R^{d}, \quad f(u) = B(u) \nabla_u H(u).
  \end{align*}
  A smooth function $(\tau,u) \in \R \times \R^{d} \mapsto  S_\tau(u) \in
  \R^{d}$ is said to be a Poisson map  iff
  \begin{align*}
    \forall u \in \R^{d}, \quad \left(\partial_u S_\tau(u)\right) B(u) \left(\partial_u S_\tau(u)\right)^T = B(S_\tau(u)).
  \end{align*}
\end{definition}

\begin{remark} \label{sec:geometry:rmk:equiv_poisson} The $\tau$-flow of a
  Poisson system is a Poisson map, and the converse is locally
  true if in addition the Casimirs (spanning the null space of $B$) are
  preserved by the flow. This result is found for instance in~\cite[Chap.
  VII, Thm. 4.5]{hairer.2006.geometric}. 
  % The proof consists in separating
  % the null space and the invertible space of $B$ with a change of
  % variable. The invertible space can be treated as in the Hamiltonian
  % case, and the null space is preserved by definition of the Casimirs. 
\end{remark}



\subsection{The linear case}


\begin{theorem} \label{sec:geometry:thm:conservation} %
  If $(\theta,u) \mapsto f_\theta(u)$ is linear w.r.t.~$u$, then
  Assumption~\ref{hyp:exist_avg_lin} is met, and $(\theta,u) \mapsto
  \Phi^\eps _\theta(u)$ and $u \mapsto F^\eps(u)$ are linear w.r.t.~$u$.
  In that case, stroboscopic averaging is a geometric procedure. More
  precisely, for $\eps$ small enough, if for all $\theta \in \T$, 
  \begin{enumerate}[(i)]
    \item $f_\theta$ is a divergence-free vector field and $X$ is of
    dimension $d < \infty$, then $F^\eps$ is also divergence-free;
    \item the quadratic form $I$ is an invariant of $f_\theta$, then it
    is an invariant of $F^\eps$;
    \item $f_\theta$ is a Hamiltonian vector field, then $F^\eps$ is
    Hamiltonian;
    \item $f_\theta$ is a $B$-Poisson vector field, then $F^\eps$ is
    $B$-Poisson.
  \end{enumerate}
\end{theorem}

Note that since $\Phi^\eps _{t/\eps} \Psi^\eps _t$ is exactly the
$t$-flow of Problem~\eqref{sec:intro:eq:ode_u}, the change of variable
also has geometric properties. Every property can be proven using the
following lemma:

\begin{lemma} \label{lemma:lin_loop} %
  At fixed $\eps > 0$, consider the linear Cauchy problem 
  \begin{equation} \label{lemma:lin_loop:pb}
    \pa_t y^\eps = L^\eps y^\eps, 
    \qquad
    y^\eps(0) = y_0 \in E ,
  \end{equation}
  in some Banach space $E$. If $\vertiii{L^\eps} < 2\pi/\eps$, then
  $y^\eps(\eps) = y_0$ if and only if $y^\eps$ is constant. 
\end{lemma}

\begin{proof}
  If~$y^\eps$ is constant, then in particular~$y^\eps(\eps) = y_0$.
  Conversly, invoking the $\eps$-periodicity of~$t \mapsto y^\eps(t)$,
  it is possible to write~$y^\eps(t)$ as a Fourier series, $y^\eps(t) =
  \sum_k y_k e^{ik \frac{2\pi}{\eps}t}$. The equation on $y^\eps$ can be
  separated into $\frac{2k\pi}{\eps} y_k = L^\eps y_k$ for all~$k \in
  \setZ$. It follows that $y_k$ is zero for all $k \neq 0$. 
\end{proof}

\begin{proof}
  From~Assumption~\ref{hyp:exist_avg_lin}, we set $\kappa > 0$ such that
  \begin{equation*}
    \vertiii{F^\eps} \leq \kappa .
  \end{equation*}
  Writing~$\varphi^\eps_t$ the $t$-flow associated with
  Problem~\eqref{sec:intro:eq:ode_u}, and we will often use the
  identity for stroboscopic times $t = \eps k$ with $k \in \setZ$, 
  \begin{equation} \label{eq:strobo_lin}
    \varphi^\eps _{\eps k} = \Psi^\eps _{\eps k} .
  \end{equation}

  \medskip\noindent%
  \textit{(i)}\indent%
  By differentiation of the determinant,
  \begin{equation*}
    \frac{\D}{\D t}\det(\Psi^\eps _t) = \tr(F^\eps) \det(\Psi^\eps _t) ,
  \end{equation*}
  with $\det(\Psi^\eps _\eps) = \det(\Psi^\eps _0) = 1$ thanks
  to~\eqref{eq:strobo_lin}, and $|\tr(F^\eps)| \leq d\kappa$ with $d$
  the dimension of~$X$. From a direct application of
  Lemma~\ref{lemma:lin_loop}, the determinant is constant for $\eps$
  small enough, i.e. $F^\eps$ is divergence-free.


  \medskip\noindent%
  \textit{(ii)}\indent%
  Since $I$ is a normal form, we may find a matrix $Q$ such that for all
  $u \in X$, 
  \begin{equation}
    I(u) = u^T Q u .
  \end{equation}
  Using~\eqref{eq:strobo_lin}, the quantity $I \circ \Psi^\eps _t$ is
  preserved at stroboscopic times, i.e. $I \circ \Psi^\eps _\eps = I$.
  Furthermore, exploiting the commutativity $\Psi^\eps _t F^\eps =
  F^\eps \Psi^\eps _t$, a differentiation yields 
  \begin{equation}
    \frac{\D}{\D t} \left( I \circ \Psi^\eps _t \right)
    = \big( F^\eps \big)^T I\circ \Psi^\eps _t
    + (I\circ \Psi^\eps _t) F^\eps ,
  \end{equation}
  which is of the form~\eqref{lemma:lin_loop:pb} with $L^\eps M =
  (F^\eps )^T M + M F^\eps$, of norm bounded by~$2\kappa$. For~$\eps$
  small enough, Lemma~\ref{lemma:lin_loop} can be applied, therefore~$I$
  is preserved by $\Psi^\eps$, i.e. it is an invariant of~$F^\eps$.

  \medskip\noindent%
  \textit{(iii)}\indent%
  Considering the symplectic structure $\Psi^\eps _t J^{-1} (\Psi^\eps
  _t)^T$, the same reasoning can be conducted, therefore $\Psi^\eps _t$
  is symplectic for $\eps$ small enough, i.e. $F^\eps$ is Hamiltonian.

  \medskip\noindent%
  \textit{(iv)}\indent%
  Up to a change of variable, we assume that the Poisson matrix~$B$ is
  of the block form 
  \begin{equation*}
    B = \left(\begin{array}{c|c}
      0 & 0 \\ \hline 0 & \Lambda
    \end{array}\right)
  \end{equation*}
  with~$\Lambda$ invertible skew-symmetric. Therefore a vector field~$G$
  is $B$-Poisson if and only if it is of the form
  \begin{equation*}
    G = \left(\begin{array}{c|c}
      0 & 0 \\ \hline * & \Lambda S
    \end{array}\right)
  \end{equation*}
  with $S$ symmetric. From~\textit{(ii)}, we know that the Casimirs (the
  zero-subspace) is preserved by~$F^\eps$, therefore the top row
  of~$F^\eps$ has to be zero. From~\textit{(iii)}, the lower-right block
  of $F^\eps$ generates a $\Lambda$-symplectic flow, which means this
  block must be of the form~$\Lambda S$. Thus,~$F^\eps$ is $B$-Poisson. 

\end{proof}


\begin{remark}
  It may be of interest to note that in the linear autonomous case $\pa_t
  u = \frac{1}{\eps} Gu + Ku$, property (i) of volume-preservation does
  not involve the dimension. Indeed differentiating the filtered change of
  variable $\Phi_\theta = e^{-\theta G} e^{\theta G^\eps}$ and taking
  the average yields 
  \begin{equation*}
    G^\eps = \LL \Phi \RR^{-1} G \LL \Phi \RR .
  \end{equation*}
  In the homological equation $\pa_\theta \Omega_\theta = \eps (
  K \Omega_\theta - \Omega_\theta K^\eps )$, we obtain 
  \begin{equation*}
    K^\eps = \LL \Phi \RR^{-1} K \LL \Phi \RR .
  \end{equation*}
  The involvement of the dimension in our proof actually
  seems purely technical, since the averaged vector field $F^\eps$ can be
  expressed as a power series in $\eps$ which converges for $\eps$ small
  enough. Our result shows that every term of the series must be
  divergence-free, but the radius of convergence of the series $\eps_0$ may
  be independent of the dimension of the space.
\end{remark}




\subsection{Approximations on bounded domains}
\label{sec:approx}


Here is what the preservation of geometric properties presented in
Section~\ref{sec:geometry} becomes. 

\begin{theorem}[Adaptation of Theorem~\ref{sec:geometry:thm:conservation}]
\hspace*{1em} \\
  Consider Assumption~\ref{hyp:exist_avg_nl} met and denote
  $\varphi^\eps _t$ the $t$-flow associated to
  Problem~\eqref{sec:intro:eq:ode_u}. Up to a reduction of~$\eps_0$, the
  following properties are satisfied up to an error of size
  $\bigO(\eps^{n+1})$~: if for all $t \in [0, T_R]$, 
  \begin{enumerate}[(i)]
    \item $u \mapsto \varphi^\eps _t(u)$ is volume-preserving on
    $\mathcal{K}_{2R}$, then $\Psi\rk n _t$ is volume-preserving on
    $\mathcal{K}_R$~;
    \item the functional $I$ is preserved by $\varphi^\eps _t$ on
    $\mathcal{K}_{2R}$ with $\mathcal{K}$ bounded, then it is preserved
    by $\Psi\rk n _t$ on $\mathcal{K}_R$~; 
    \item $\varphi^\eps _t$ is symplectic on $\mathcal{K}_{2R}$, then
    $\Psi\rk n _t$ is symplectic on $\mathcal{K}_R$~;
    \item $\varphi^\eps _t$ is $B$-symplectic and preserves Casimirs on
    $\mathcal{K}_{2R}$, then $\Psi\rk n _t$ is $B$-symplectic and
    preserves Casimirs on $\mathcal{K}_R$.
  \end{enumerate}
  Note that since $\Phi\rk n _\theta = \varphi^\eps _{\eps\theta} \circ
  \Psi\rk n _{-\eps\theta} + \bigO(\eps^{n+1})$, these properties are
  also true for $\Phi\rk n _\theta$, up to terms of
  size~$\bigO(\eps^{n+1})$. It is therefore possible to modify $\Phi\rk
  n$ and $F\rk n$ and have these properties met exactly.
\end{theorem}

\begin{proof}
As can be seen in the proof of
Theorem~\ref{sec:geometry:thm:conservation}, every property can be proven
in the same way. Therefore we will only describe how to
prove~\textit{(iii)}, as it is probably the most interesting property for
the majority of readers. We refer to the other proof for the adaptation to
other properties. 

Set $(t,u) \mapsto \Delta_t(u)$ the deviation from symplecticity, 
\begin{equation*}
  \Delta_t = \big(\pa_u \Psi_t\rk n\big) J^{-1} 
      \big( \pa_u \Psi_t\rk n \big) ^T 
    - J^{-1} ,
\end{equation*}
defined and bounded for $u \in \mathcal{K}_{R_n}$ 
Thanks the periodicity of~$\Phi\rk n$, $t \mapsto \Delta_t$ is almost zero at
stroboscopic times, meaning that for all $k \in \N$ such that $\eps k \leq
T_R$, since $\Psi\rk n _{\eps k} = \varphi^\eps _{\eps k} + \bigO(
\eps^{n+1})$,
\begin{equation*}
  \Delta_{\eps k} 
  = \big(\pa_u \varphi ^\eps _{\eps k}\big) J^{-1} 
      \big( \pa_u \varphi^\eps _{\eps k} \big) ^T 
    - J^{-1} + \bigO( \eps^{n+1} )
  = \bigO( \eps^{n+1} ) .
\end{equation*}
For now let us conduct our reasoning on $(t,u) \in [0,\eps] \times
\K_R$. Setting $L_t M = \pa_u F\rk n ( \Psi_t\rk n ) M + M \big( \pa_u
F\rk n (\Psi_t\rk n ) \big)^T $ and $S_t = L_t J^{-1}$, it satisfies
\begin{equation} \label{sec:geometry:eq:ode_Delta}
  \pa_t \Delta_t = L_t\, \Delta_t + S_t,
  \quad\text{i.e.}\quad
  \Delta_t = \Delta_0 + \int_0^t L_\tau\, \Delta_\tau \dd \tau 
    + \int_0^t S_\tau \, \dd \tau .
\end{equation}
We want to prove $\sup_{0 \leq t \leq \eps} \| \Delta_t \|_R = \bigO(\eps^{n+1}
)$. To that effect, introduce the norm~$\|\cdot\|_{\eps, \rho}$ and the
radii~$R_k$, 
\begin{equation*}
  \| g \|_{\eps, \rho} = \sup_{0 \leq t \leq \eps} \| g_{t} \|_{\rho}
  \qquad\text{and}\qquad
  R_k = R + k r_n
  \quad\text{with}\quad
  r_n = \frac{R}{n+1} ,
\end{equation*}
and set $\alpha > 0$ such that $\| \Delta_0 \|_{2R}, \| \Delta_\eps
\|_{2R} \leq \alpha \eps^{n+1}$. Gronwall's lemma in the integral form of
$\Delta_t$ yields 
\begin{equation} \label{sec:approx:eq:gronwall}
  \| \Delta \|_{\eps, R} 
  \leq \big( \alpha \eps^{n+1} + \eps \| S \|_{\eps, R} \big)
    e^{\eps \| L \|_{\eps, R}} ,
\end{equation}
therefore we want to show $\| S \|_{\eps, R} = \bigO( \eps^{n} )$ so
that $\Delta_t = \bigO(\eps^{n+1})$. Because $S$ is transported by $F\rk
n$, i.e. $S_t = S_0 \circ \Psi\rk n _t$, it is possible to bound $S_t$
on some space $\mathcal{K}_\rho$ by the norm of $S_0$ on a larger space.
In particular, assuming $\eps_0 \leq R/(2M)$, i.e. $\eps \leq r_n/(2M)$,
\begin{equation} \label{sec:geom:eq:transported_bound}
  \| S \|_{\eps, R_k} 
  \leq \| S_0 \| _{R_k + r_n/2} 
  \leq \| S_0 \| _{R_{k+1}}
\end{equation}
since $\| \Psi\rk n _t - \id \|_{R_n} \leq t M $. Additionally
from~\eqref{sec:geometry:eq:ode_Delta} evaluated at $t = \eps$, we
gather 
\begin{equation} \label{sec:geom:eq:avg_S}
  \left| \int_0^\eps S_t \D t \right|
  \leq 2\alpha \eps^{n+1} 
    + \int_0^\eps \|L_t\|_{R} \D t \ \| \Delta \|_{\eps, R} .
\end{equation}
An integration by parts transforms the left integral, $\int_0^\eps S_t
\D t = \eps S_0 + \int_0^\eps (\eps - t) \pa_t S_t \D t$, and because
$S_t$ is transported by $F\rk n$, we may use a Cauchy estimate 
\begin{equation*}
  \| \pa_t S_t \|_R 
  \leq \left\| (\pa_u S_0 \cdot F\rk n) \circ \Psi^\eps _t \right\|_R
  \leq \left\| \pa_u S_0 \cdot F\rk n \right\|_{R+r_n/2}
  \leq \frac{M}{r_n/2} \| S_0 \|_{R_1} 
  \leq \frac{1}{\eps_n} \| S_0 \|_{R_1} .
\end{equation*}
Using the integration by parts along with this estimate
in~\eqref{sec:geom:eq:avg_S}, we obtain
\begin{equation*} \label{sec:geom:eq:tmp_S0}
  \eps \| S_0 \|_R
  \leq \frac{\eps}{2\eps_n}\| S_0 \|_{R_1}
    + 2\alpha \eps^{n+1} 
    + \int_0^\eps \|L_t\|_{R} \D t \ \| \Delta \|_{\eps, R} .
\end{equation*}
Since $L_t$ is also transported by $F\rk n$, the integral can also be
bounded, $\int_0^\eps \| L_t \|_R \D t \leq \eps \| L \|_{\eps, R} \leq
\eps \| L_0 \|_{R + r_n/2}$, and by definition along with a Cauchy
estimate, 
\begin{equation*}
  \| L_0 \| _{R + r_n/2} 
  \leq 2 \| \pa_u F^\eps \|_{R + r_n/2}
  \leq \frac{1}{r_n/2} M \leq \frac{1}{\eps_n} .
\end{equation*}
This bound, as well as~\eqref{sec:approx:eq:gronwall} can be injected
into~\eqref{sec:geom:eq:tmp_S0} to yield 
\begin{equation*}
  \| S_0 \|_R
  \leq \frac{\eps}{\eps_n} \left(
    \frac{1}{2} + e^{\eps/\eps_n} 
  \right) \| S_0 \|_{R_1} 
  + (2 + e^{\eps/\eps_n}\eps/\eps_n) \alpha \eps^n
  \leq \frac{4\eps}{\eps_n} \| S_0 \|_{R_1} + 5\alpha \eps^n .
\end{equation*}
The same reasoning can be conducted on any $\mathcal{K}_{R_k}$ to obtain
\begin{equation*}
  \| S_0 \| _{R_k} 
  \leq \frac{4\eps}{\eps_n} \| S_0 \|_{R_{k+1}} + 5\alpha \eps^n
\end{equation*}
therefore, by successive injections,
\begin{equation*}
  \| S_0 \| _R \leq \left( \frac{4\eps}{\eps_n} \right)^{n+1} \|S_0\| _{2R}
  + 5\alpha \eps^n \sum_{k = 0}^n \left(\frac{4\eps}{\eps_n}\right)^k
\end{equation*}
therefore, because $\| S_0 \|_{2R}$ is bounded by definition, if $\eps$
is small enough, 
\begin{equation*}
  \| S_0 \|_{R_1} = \bigO(\eps^n),
  \qquad\text{and in turn}\qquad
  \| \Delta \|_{\eps, R} = \bigO(\eps^{n+1}) .
\end{equation*}
This result is also true on all intervals of the form $[k\eps,
(k+1)\eps]$, therefore $(t,u) \mapsto \Psi^\eps _t(u)$ is symplectic up
to terms of order~$\bigO(\eps^{n+1})$. 


\end{proof}