
\clearemptydoublepage
\chapter{La moyennisation en bref}
\label{chap:avg}

Lors de ma troisième année de thèse, j'ai eu l'occasion d'un peu plus me
pencher sur les méthodes de moyennisation, et notamment de rédiger un
mini-article compilant certains résultats du sujet. 

\todo[inline]{Ajouter quelques résultats numériques}

% \section{Présentation d'une méthode}


% \subsection{L'équation homologique}

% Dérivation de l'équation homologique

% Distinction entre averaging standard et stroboscopique


% \subsection{Définition d'une décomposition approchée}

% Relation de récurrence et résultat sur les bornes

% Discussion autour de la méthode pour les résultats (boules imbriquées,
% estimations de Cauchy...)



% \section{Contexte d'un problème autonome}

% \begin{equation}
%     \pa_t y = \frac{1}{\eps} G(y) + K(y)
% \end{equation}
% On décompose
% \begin{equation}
%     y^\eps(t) = \Omega^\eps _{t/\eps} \circ \Psi^\eps _t 
%     \circ \big( \Omega^\eps _0 \big)^{-1}
% \end{equation}

% \subsection{Un résultat géométrique}

% $\Omega$ est un flot, et commute avec $\Psi$. 


% \subsection{Cas d'un opérateur linéaire}

% Averaging standard : crochets de Lie

% Formes normales


% \section{Aspect numérique}

% Si on ne connaît pas le défaut, il est clair qu'on peut calculer
% numériquement 
% \begin{empheq}{equation}
%     \pa_t v\rk n = F\rk n ( v\rk n ) 
% \end{empheq}
% et alors 
% \begin{empheq}{equation}
%     u^\eps(t) = \Phi\rk n _{t/\eps} \big( v\rk n (t) \big)
%     + \bigO(\eps^{n+!})
% \end{empheq}
% Mais en fait si on montre ça, on peut montrer mieux (en supposant un peu de régularité). Section basée principalement sur l'article avec Gilles. 

% \subsection{Définition d'un nouveau problème}

% Micro-macro ou pullback

% Raideur ``retardée''

% \subsection{Convergence uniforme}

% Résultat de convergence uniforme

% Présentation de schémas intégraux et composition de schémas 

\section{Introduction}
\label{section:introduction}


This paper compiles results pertaining to \textit{high-order averaging},
that is to say the problem of separating the slow and fast dynamics in a
highly-oscillatory setting. The type of problem we consider may arise in
many realistic physical models, such as molecular
dynamics~\cite{garciaarchilla.1998.long} or charged-particle dynamics under a
strong magnetic field~\cite{chartier.2020.uniformly,
frenod.2009.long,frenod.2000.long}. It may also arise in functional
spaces; two examples are the nonlinear Klein-Gordon equation in the
nonrelativistic limit regime~\cite{bao.2014.uniformly,
bao.2019.comparison, chartier.2020.new} and the oscillatory nonlinear
Schrödinger equation~\cite{chartier.2015.uniformly,
castella.2015.stroboscopic}.


Mathematically speaking, we consider problems with forced oscillations of
the form 
\begin{equation} \label{sec:intro:eq:ode_u}
  \pa_t u(t) = f_{t/\eps}\big( u(t) \big) , 
  \qquad 
  u(0) = u_0 \in X, 
  \qquad
  t \in [0, 1] 
\end{equation}
where \( X \) is a Banach space of norm \( | \cdot | \), the
non-autonomous vector field \( (\theta,u) \in \T \times X \mapsto
f_\theta(u) \) is 1-periodic w.r.t. \( \theta \) on the torus \( \T :=
\R/\Z \). As mentioned, the space \(X\) may be simply \( \R^d \), in which
case the problem is a simple ordinary differential equation in finite
dimension, or it may be a functional space, such as the space of
square-integrable function \( L^2(\R) \). 
%
Note that this type of equation can result from the \textit{filtering} of
an autonomous equation
\begin{equation} \label{sec:intro:eq:ode_auto}
  \dot v^\eps = \frac{1}{\eps} G(v) + K(v), \quad v^\eps(0)=v_0 \in X
\end{equation}
if $G$ generates a $1$-periodic flow $(\theta, u) \mapsto \chi_\theta(u)$.
It links to~\ref{sec:intro:eq:ode_u} using the filtered variable 
$u^\eps(t) = \chi_{-t/\eps}\big(v^\eps(t) \big)$ which
follows an equation of the form~\eqref{sec:intro:eq:ode_u} with
$f_{\theta}(u) = \left(\partial_u \chi_{-\theta}\cdot K \right) \circ
\chi_{\theta}(u)$. 

%

The approach of averaging can be summarized as the decomposition of the
solution \( u(t) \) into a \textit{near-identity, rapidly oscillating}
change of variable \(\Phi^\eps_{t/\eps} \) and the dynamics of an
\textit{average} autonomous vector field \( F^\eps \). This can be written
\begin{equation} \label{sec:intro:eq:decomp_u}
  u(t) = \Phi^\eps_{t/\eps} \circ \Psi^\eps_t \circ 
    \big( \Phi^\eps_0 \big)^{-1} (u_0), 
\end{equation}
where \( (\theta,u) \mapsto \Phi^\eps_\theta(u) \) is 1-periodic w.r.t.
\( \theta \) and \( (t,u) \mapsto \Psi^\eps_t(u) \) is the $t$-flow
associated to \( F^\eps \), i.e. for $(t,u) \in [0,1] \times X$, 
\begin{equation}
  \frac{\dd}{\dd t} \Psi^\eps_t(u) = F^\eps \big( \Psi^\eps_t(u) \big) ,
  \qquad \Psi^\eps_0 = \id . 
\end{equation}
We refer to Lochak-Meunier~\cite{lochak.1988.multiphase} and
Sanders-Verhulst-Murdock~\cite{sanders.2007.averaging} for textbooks on
these issues. Since the goal is to separate the fast periodic part in
$\theta$ and the slow drift in $t$, averaging is can be seen as analogous
to the two-scale expansion $u^\eps(t) = U^\eps(t, \theta) |_{\theta =
t/\eps}$ often found in the context of high-frequency PDEs. It
is also similar to WKB expansions~\cite{wentzel.1926.eine,kramers.1926.wellenmechanik,brillouin.1926.remarques}, since in some sense $\Phi^\eps$
captures the rapid phase dynamics and $\Psi^\eps$ the slow amplitude
changes. Admittedly, these dynamics are usually more intertwined in
averaging than in WKB expansions, but this allows the preservation of
geometric structures such as volume invariance or symplecticity. This is
the subject of Section~\ref{sec:geometry}.

In this work, we shall not discuss specific methods to compute the
periodic change of variable or the averaged vector fields, the traditional
approach dating back to~\cite{perko.1969.higher} consists in assuming the
maps are power series in~$\eps$ and injecting the ansatz $\Phi^\eps_\theta
= \id + \sum_{n \geq 1} \Phi^{[n]}_{\theta}$
in~\eqref{sec:intro:eq:decomp_u} and identifying like terms in~$\eps$.
This formal series approach has been revisited using B-series or the
Magnus expansion in~\cite{chartier.2010.higher,
chartier.2012.formal, casas.2019.continuous}.
%
Another approach is that of ``successive substitution'' dating back
to~\cite{neishtadt.1984.separation} (albeit in a slightly different
context), and more recently in~\cite{castella.2015.stroboscopic,
chartier.2020.new}. This circumvents the ansatz and seems to yield better
convergence properties. Both approaches coincide formally. 
%
Our goal in this paper is to present known results in a new light, and
offer original proofs without having to invoke any ansatz, formal series
or construction process. 

\medskip%
A particularly well-studied case is that of the autonomous problems with
linearly-generated oscillations (i.e. linear $G$), for which the problem
of averaging can often be reduced to finding some $\theta$-independent
change of variable $\big( \Phi^\eps_0 \big) ^{-1}$, or some equivalent. It
is then possible to consider the problem on this new variable
$\big(\Phi^\eps_0 \big)^{-1} (u(t))$. As such, a link can be made with
normal forms, and specifically Birkhoff's forms technique have been
considered in this context by Bambusi~\cite{bambusi.2003.birkhoff, bambusi.2005.birkhoff-lewis, bambusi.2006.birkhoff, bambusi.2008.birkhoff},
Bourgain~\cite{bourgain.1996.construction},
Colliander~\cite{colliander.2010.transfer, colliander.2012.remark} and
Grébert~\cite{bambusi.2006.birkhoff, grebert.2011.energy,
grebert.2012.resonant}, to mention only a few. We offer some insight on
this approach in Section~\ref{sec:autonomous:rmk:std_link}.
%
Note that many of these works consider the setting of multiple
non-resonant frequencies, which is akin to considering $f$ as a function
of multiple phases $\theta_1, \theta_2, \ldots$
in~\eqref{sec:intro:eq:ode_u}. This setting has also be studied with
averaging using diophantine approximations
in~\cite{chartier.2017.convergence} and with $B$-series
in~\cite{chartier.2012.higher}. 

\bigskip %
In Section~\ref{sec:presentation}, we present some general properties of
averaging, detailing the differences between standard and stroboscopic
averaging. In Section~\ref{sec:autonomous}, we present some remarkable
properties of averaging in the autonomous case. In
Section~\ref{sec:geometry}, we restrain ourselves to stroboscopic
averaging, and present some of its geometric properties. Finally, in
Section~\ref{sec:approx}, we discuss what becomes of the previous results
in the case of a bounded domain. 


\section{A brief presentation of averaging} \label{sec:presentation}


Differentiating~\eqref{sec:intro:eq:decomp_u} w.r.t. \( t \) generates
\begin{equation*}
  f_{t/\eps} \circ \Phi^\eps_{t/\eps} \big( v(t) \big) 
  = \frac{1}{\eps} \pa_\theta \Phi^\eps_{t/\eps} \big( v(t) \big)
  + \pa_u \Phi^\eps_{t/\eps}\big( v(t) \big) \cdot F^\eps \big( v(t) \big)
\end{equation*}
with \( v(t) = \Psi^\eps_t \circ \big( \Phi^\eps_0 \big)^{-1} (u_0) \) the
average dynamics. By separating the rapid oscillations in $t/\eps$ and the
slow drift in $t$, one obtains the homological equation, which is for
$(\theta, u) \in \T \times X$, 
\begin{equation} \label{sec:presentation:eq:homol}
  \pa_\theta \Phi^\eps_{\theta} (u)
  = \eps \left( f_{\theta} \circ \Phi^\eps_{\theta} (u) 
    - \pa_u \Phi^\eps_{\theta} (u) \, F^\eps (u) \right) .
\end{equation}
Now taking the average, it appears that the change of variable $\Phi^\eps$
alone stores the information of the averaged vector field. Indeed, for $u$
in $X$, $F^\eps(u)$ is given by
\begin{equation}
  F^\eps (u) = \Big( \pa_u \LL \Phi^\eps \RR (u) \Big)^{-1} 
        \LL f \circ \Phi \RR (u) ,
\end{equation}
where $\LL \,\cdot\, \RR$ denotes the average, defined for a periodic map
$ (\theta, u) \in \T \times X \mapsto \varphi_\theta(u)$ by
\begin{equation}
  \LL \varphi \RR (u) = \int_0^1 \varphi_\theta (u) \dd \theta .
\end{equation}
Up to a change of variable, $\Phi^\eps$ is assumed to be near identity,
i.e. 
\begin{equation}
  \Phi^\eps = \id + \bigO(\eps) .
\end{equation}
It is known that equation~\eqref{sec:presentation:eq:homol} generally has no
rigorous solution, only solutions as a formal series in $\eps$. An example
where this divergence is observed can be found
in~\cite{chartier.2010.higher}. However the series converges in the
case where $f_\theta$ is a linear and bounded operator, for $\eps$ small
enough. 

\bigskip
Perhaps the most straighforward approach to solve the homological equation
is a fixed point method separating the right-hand side of the equation (of
size $\eps$) and the left (of size $1$). It immediately appears that a
closure condition on $\Phi^\eps$ is needed to properly invert
$\pa_\theta$. Two choices are often considered.

\smallskip\noindent
\textit{Standard averaging:} 
%
$ \LL \Phi^\eps \RR = \id ,$ 

\noindent\hfil\parbox[t]{0.85\textwidth}{%
also called the Chapmann-Enskog method in the
context of kinetic theory (see~\cite{chartier.2020.averaging}). This
choice circumvents the computation of an inverse, as then $F^\eps = \LL f
\circ \Phi^\eps \RR$, therefore computations are not too costly. As
highlighted in~\cite{chartier.2020.derivative}, in numerical contexts
the $\pa_u \Phi^\eps \cdot F^\eps$-term can be replaced by a
finite-differences approximation up to some order in $\eps$, thereby 
removing the need to compute an exact derivative and making automatic 
computations much simpler.
}\hfil%

\medskip\noindent
\textit{Stroboscopic averaging:}
\( \Phi^\eps_0 = \id \),

\noindent\hfil\parbox[t]{0.85\textwidth}{%
for which the solution \( u(t) \) coincides with
the average \( \Psi^\eps_t(u_0) \) at ``stroboscopic'' times \( t \in \eps
\N \). This produces more complex computations but renders fairly
straighforward the conservation of geometric properties, such as energy
preservation or symplectic structure. 
}\hfil%

\medskip\noindent %
We shall focus on the properties of stroboscopic averaging in the upcoming
section, but it is important to keep in mind that these choices are
conjugate. Indeed, the latter can be obtained from the former by setting 
\begin{equation*}
  \Phi^{strob} = \Phi^{std} \circ \big( \Phi_0^{std} \big)^{-1} 
  \quad
  \text{and} 
  \quad
  \Psi^{strob} 
  = \Phi_0^{std} \circ \Psi^{std} \circ \big( \Phi_0^{std} \big)^{-1} ,
\end{equation*}
i.e. $F^{strob} = \left( \pa_u \Phi_0^{std} \cdot F^{std} \right) \circ
\big( \Phi_0^{std} \big)^{-1}$. Conversely, standard averaging can be
obtained from stroboscopic averaging with the relations
\begin{equation} \label{sec:presentation:eq:strob2std}
  \Phi^{std} = \Phi^{strob} \circ \bLL \Phi^{strob} \bRR^{-1} 
  \quad
  \text{and} 
  \quad
  \Psi^{std} 
  = \bLL\Phi^{strob}\bRR \circ \Psi^{strob} \circ 
    \bLL\Phi^{strob}\bRR^{-1} .
\end{equation}
Thus some properties of standard averaging will also be discussed. 



\section{Commutation of flows in the autonomous case} 
\label{sec:autonomous}

In this section we restrict ourselves to the case of an autonomous
equation of the form 
\begin{align} \label{sec:autonomous:eq:pb_v}
  \dot v^\eps = \frac{1}{\eps} G(v^\eps) + K(v^\eps), 
  \quad v^\eps(0) = v_0 \in X
\end{align}
where $G$ and $K$ are smooth function from a Banach space $X$ into itself
and where $G$ generates a $1$-periodic flow $(\theta,u) \mapsto
\chi_\theta(u)$. The approach is the same as for the non-autonomous
problem, which is to say we search a solution under the form 
\begin{align}
  v^\eps(t) = \Omega^\eps_{t/\eps} \circ \Psi^\eps_t \circ (\Omega^\eps_0)^{-1} (v_0)
\end{align}
where $\theta \mapsto \Omega^\eps_\theta$ is assumed to be $1$-periodic and
$\Psi^\eps_t$ is the $t$-flow associated to the averaged vector flow
$K^\eps$. The reasons why the notation of the change of variable changed
but not that of the average flow will be made clear as this section
progresses. The homological equation is now 
\begin{equation} \label{sec:autonomous:eq:homol}
  \quad \pa_\theta \Omega^\eps_\theta(u) - G \circ \Omega^\eps_\theta(u) 
  = \eps \Big( K \circ \Omega^\eps_\theta(u) 
    - \pa_u \Omega^\eps_\theta(u) \, K^\eps(u) \Big) .
\end{equation}

It appears that the closure condition of standard averaging must be
reconsidered. Indeed, in the limit $\eps \rightarrow 0$, the change of
variable $\Omega^\eps_\theta$ approaches $\chi_{\theta+\theta_0}$ for some
initial phase $\theta_0$. Consider for instance the case $G(u) =
2\pi\begin{pmatrix} -u_2 \\ u_1 \end{pmatrix} = 2\pi Ju$, then clearly
choosing the standard closure condition $\LL \Omega^\eps \RR = \id$ cannot
hold, as $\LL \chi \RR = 0$. 
%
Rather than discarding standard averaging altogether, we may
\textit{filter} the equation, which is to say transform it into a
forcibly-oscillating problem by left-multiplying it by $\pa_u
\chi_{-\theta+\theta_1} \big(\Omega^\eps_\theta \big)$ for some arbitrary
phase $\theta_1$. Define the filtered change of variable
$\Phi^\eps_{\theta, \theta_1} = \chi_{-\theta + \theta_1} \circ
\Omega^\eps_{\theta}$, it satisfies\footnote{ %
  This homological equation can also be obtained directly by considering
  the filtered problem of form~\eqref{sec:intro:eq:ode_u} satisfied by
  $u^\eps_{\theta_1}(t) = \chi_{-t/\eps+\theta_1}(v^\eps(t))$, which is $
  \pa_t u^\eps_{\theta_1}(t) = f_{t/\eps, \theta_1} \big( u^\eps
  _{\theta_1} (t) \big). $ %
}
\begin{equation} \label{sec:autonomous:eq:filt_homol}
  \pa_\theta \Phi_{\theta, \theta_1} (u)
  = \eps\Big( f_{\theta, \theta_1} \circ \Phi_{\theta, \theta_1}(u) - \pa_u \Phi_{\theta, \theta_1}(u) \, K^\eps(u) \Big) 
\end{equation}
with $f_{\theta, \theta_1}(u) = \left(\partial_u \chi_{-\theta +
\theta_1}\cdot K \right) \circ \chi_{\theta-\theta_1}(u)$. Note that we
exploited the identity $\pa_\theta \chi_\theta = G \circ \chi_\theta =
\pa_u \chi_\theta \, G$. 
%
Take now the average on $\theta$ of~\eqref{sec:autonomous:eq:filt_homol},
\begin{equation} \label{sec:autonumous:eq:filt_homol_avg}
  0 = \eps\Big( 
    \bLL f_{\bigcdot, \theta_1}  \circ \Phi_{\bigcdot, \theta_1} \bRR (u) 
    - \pa_u \bLL \Phi_{\bigcdot, \theta_1} \bRR (u) \, K^\eps(u) 
  \Big) . 
\end{equation}
The standard choice of closure condition therefore seems to be $\LL
\Phi_{\bigcdot, \theta_1} \RR = \id$, i.e. $\Omega^\eps_\theta$ close to
$\chi_{\theta - \theta_1}$. Remember however that the phase shift
$\theta_1$ is arbitrary, therefore there are an infinite number of
standard closure conditions, the canonical one being $\LL \chi_{-\theta}
\circ \Omega^\eps_\theta \RR = \id$. 

Whatever the closure condition, it is possible to obtain $K^\eps$
from~\eqref{sec:autonumous:eq:filt_homol_avg}, since $\pa_u \LL
\Phi^\eps_{\bigcdot, \theta_1} \RR$ is invertible. Indeed, assuming that
$\Omega^\eps_\theta$ is close to $\chi_{\theta + \theta_0}$, all filtered
changes of variable satisfy
\begin{equation*}
  \Phi^\eps_{\theta, \theta_1} 
  = \chi_{-\theta + \theta_1} 
    \circ \big( \chi_{\theta + \theta_0} + \bigO( \eps ) \big)
  = \chi_{\theta_1 + \theta_0} + \bigO(\eps) .
\end{equation*}
This generates the identity
\begin{equation} \label{sec:autonomous:eq:filt_avg_map}
  K^\eps(u) = 
  \Big( \pa_u \bLL \chi_{-\theta+\theta_1} 
    \circ \Omega^\eps _\theta \bRR (u) \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta+\theta_1} \cdot K) 
    \circ \Omega^\eps _\theta \BRR (u) .
\end{equation}
Defining an operator extracting the average behaviour 
\begin{equation} \label{sec:autonomous:def:avg_op}
  \mathcal{A}^{\theta_1}[\varphi] := 
  \big( \pa_u \bLL \chi_{-\theta+\theta_1} 
    \circ \varphi_\theta \bRR \big) ^{-1} 
  \bLL (\pa_u \chi_{-\theta+\theta_1} \cdot K) 
    \circ \varphi _\theta \bRR , 
\end{equation}
the change of variable $\Omega^\eps$ may be
defined as the unique solution to the homological equation 
\begin{equation} \label{sec:autonomous:eq:only_Omega_homol}
  \pa_\theta \Omega^\eps _\theta - G \circ \Omega^\eps _\theta
  = \eps \big( K \circ \Omega^\eps _\theta 
    - \pa_u \Omega^\eps _\theta \cdot \mathcal{A}^{\theta_1}[\Omega^\eps] 
  \big) 
\end{equation}
that is 1-periodic and satisfies some closure condition. Note that the
above equation is considered with fixed $\theta_1$, but modifying this
phase has no impact on the definition of $\Omega^\eps$. Linking
with~\eqref{sec:autonomous:eq:homol}, this may be restated as
\begin{equation*}
  \forall \theta_1 \in \T, \qquad
  K^\eps = \mathcal{A}^{\theta_1}[\Omega^\eps] 
  = \mathcal{A}^{0}[\Omega^\eps] . 
\end{equation*}
Thanks to this invariance, a group relation may be found in the case of
stroboscopic averaging, summarized by the following proposition.

%

\begin{proposition} \label{sec:autonomous:prop:phigroup} %
  When considering stroboscopic averaging, for all $\theta$ and all
  $\theta_0$, the following group relation is satisfied 
  $$
    \Omega^\eps_{\theta} \circ \Omega^\eps_{\theta_0} 
    = \Omega^\eps_{\theta + \theta_0}.
  $$
  Equivalently, there exists a vector field $G^\eps$ such that 
  $$
  \forall \theta, \ \forall u, \qquad 
  \frac{\dd}{\dd \theta} \Omega^\eps_\theta(u) 
  = G^\eps \circ \Omega^\eps_\theta(u).
  $$
\end{proposition}
\begin{proof}
Consider the $\theta$-map  
$$
\widetilde \Omega^\eps_{\theta} 
= \Omega^\eps_{\theta+\theta_0} \circ (\Omega^\eps_{\theta_0})^{-1}.
$$
Writing equation~\eqref{sec:autonomous:eq:homol} with $\theta$ replaced by
$\theta+\theta_0$ and $(\Omega^\eps_{\theta_0})^{-1}(u)$ in lieu of $u$,
we obtain with all maps evaluated in $u$, 
\begin{equation} \label{sec:autonomous:eq:tilde_homol}
  \partial_\theta \widetilde\Omega^\eps_{\theta}
  - G \circ \widetilde \Omega^\eps_{\theta}
  = \eps\left( K \circ \widetilde \Omega^\eps_{\theta}
    - \partial_u \widetilde \Omega^\eps_{\theta} \cdot 
      \left(\partial_u (\Omega^\eps_{\theta_0})^{-1} \right)^{-1} \cdot 
      K^\eps \circ (\Omega^\eps_{\theta_0})^{-1} 
  \right) .
\end{equation}
The new averaged vector field $\widetilde{K}^\eps = \left(\partial_u
(\Omega^\eps_{\theta_0})^{-1}\right)^{-1} \cdot K^\eps \circ
(\Omega^\eps_{\theta_0})^{-1} $ can be written 
\begin{align*}
  \widetilde{K}^\eps = &
  \Big( \Big( \pa_u \bLL \chi_{-\theta+\theta_0} 
      \circ \Omega^\eps _\theta \bRR \Big) 
    \circ \big( \Omega^\eps_{\theta_0} \big)^{-1} \cdot
    \pa_u (\Omega^\eps_{\theta_0})^{-1} \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta+\theta_0} \cdot K) 
    \circ \Omega^\eps _\theta  \circ (\Omega^\eps_{\theta_0})^{-1} \BRR ,
\end{align*}
exploiting~\eqref{sec:autonomous:eq:filt_avg_map} with $\theta_1 =
\theta_0$. The derivatives can be concatenated into $\pa_u \bLL
\chi_{-\theta + \theta_0} \circ \Omega^\eps _\theta \circ (\Omega^\eps
_{\theta_0})^{-1} \bRR$. Exploiting then the phase invariance of the
average, i.e. $\LL \varphi_{\theta} \RR = \LL \varphi_{\theta + \theta_0}
\RR$, the identity appears 
\begin{equation*}
  \widetilde{K}^\eps =
  \Big( \pa_u \bLL \chi_{-\theta} 
    \circ \widetilde\Omega^\eps _\theta \bRR \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta} \cdot K) 
    \circ \widetilde\Omega^\eps _\theta \BRR 
  = \mathcal{A}^{0}[\widetilde{\Omega}^\eps] .
\end{equation*}
Injecting this into~\eqref{sec:autonomous:eq:tilde_homol}, we find that
$\widetilde{\Omega}^\eps$ is a 1-periodic map which satisfies an equation
of the form~\eqref{sec:autonomous:eq:only_Omega_homol}. As we only
consider stroboscopic averaging, $\widetilde{\Omega}^\eps$ also satisfies
the same closure condition as $\Omega^\eps$, which is to say
$\widetilde\Omega^\eps _0 = \Omega^\eps _0 = \id$. Therefore, the two maps
coincide and the proof is over. 

\end{proof}
%
\begin{proposition} \label{sec:autonomous:prop:commut}
  The flows $\theta \mapsto \Omega^\eps_\theta$ and $t \mapsto
  \Psi^\eps_t$ commute with each other, i.e.
  $$
  \forall \theta, \quad \forall t, \qquad \Omega^\eps_\theta \circ \Psi^\eps_{t} = \Psi^\eps_{t} \circ \Omega^\eps_\theta.
  $$
  Equivalently, the vector fields $G^\eps$ and $K^\eps$ commute with each
  other, i.e.
  $$
  [G^\eps,K^\eps]=0
  $$
  where $[\cdot,\cdot]$ is the usual Lie-bracket.
\end{proposition}
\begin{proof}
  The group law for $t \mapsto \Omega^\eps_{t/\eps} \circ \Psi^\eps_{t}$
  (recall that equation (\ref{sec:autonomous:eq:pb_v}) is autonomous) gives for all $s$
  and $t$
  \begin{align} \label{eq:groupphipsi}
    \left(\Omega^\eps_{s/\eps} \circ \Psi^\eps_{s} \right) \circ \left(\Omega^\eps_{t/\eps} \circ \Psi^\eps_{t} \right) = \Omega^\eps_{(s+t)/\eps} \circ \Psi^\eps_{s+t}.
  \end{align}
  The $t$-flow $\Psi^\eps_t$ satisfies a group-law by construction and
  owing to Proposition \ref{sec:autonomous:prop:phigroup}, this is also
  the case for $\Omega^\eps_\tau$. Hence, we can compose equation
  (\ref{eq:groupphipsi}) from the left by $\Omega^\eps_{-s/\eps}$ and from
  the right by $\Psi^\eps_{-t}$ and obtain 
  $$
  \Psi^\eps_{s}  \circ \Omega^\eps_{t/\eps} = \Omega^\eps_{t/\eps} \circ \Psi^\eps_{s}.
  $$
  The commutation of the vector fields then follows in a standard way. 
\end{proof}

Note that this result can also be obtained from the proof of
Proposition~\ref{sec:autonomous:prop:phigroup}, since there we find 
\begin{equation*}
  K^\eps = \widetilde{K}^\eps = \left(\partial_u
    (\Omega^\eps_{\theta_0})^{-1}\right)^{-1} \cdot K^\eps \circ
    (\Omega^\eps_{\theta_0})^{-1} ,
\end{equation*}
i.e. $K^\eps$ is invariant when conjugated by $\Omega^\eps_{\theta_0}$.


\begin{remark} \label{sec:autonomous:rmk:std_link} If $G$ is linear, then
  differentiating $\Phi^\eps _{\theta, \theta_0}$ w.r.t. $\theta$ and
  taking the average generates
  \begin{equation*}
    G^\eps 
    = \BLL \pa_u \Phi^\eps_{\theta, \theta_0} \BRR^{-1} G \, 
      \bLL \Phi^\eps _{\theta, \theta_0} \bRR 
    = \big( \pa_u \Omega_0^{std} \cdot G \big) 
      \circ \big( \Omega_0^{std} \big)^{-1}
  \end{equation*}
  if $\Omega^{std}$ is such that $\LL e^{-(\theta-\theta_0) G}
  \Omega^{std} \RR = \id$ owing to~\eqref{sec:presentation:eq:strob2std}.
  Furthermore the average vector field $K^{std}$ commutes with $G$, thanks
  to the identity
  \begin{equation*}
    [G,K^{std}] 
    = \left[ \mathbb S (G^\eps) , \mathbb S (K^\eps) \right]
    = \mathbb S \big( [G^\eps , K^\eps] \big)
    = 0
  \end{equation*}
  with $\mathbb S (F) = \big( \pa_u \Phi_0^{std} \cdot F \big) \circ
  \big( \Phi_0^{std} \big)^{-1}$. In other words, the change of variable
  $\big( \Omega^{std}_0 \big)^{-1}$ transforms the perturbed vector field
  $G + \eps K$ into $G + \eps K^{std}$, where $G$ and $K^{std}$ commute.
  This links to the vision of normal forms as presented in~\cite[Chap.
  IX]{sanders.2007.averaging}.
\end{remark}



\section{Stroboscopic averaging and geometry}
\label{sec:geometry}

We start by introducing some geometric properties, then prove they are
preserved by stroboscopic averaging.


\subsection{Definitions of geometric properties}

\begin{definition}
  Define the matrix $J \in {\cal M}(\R^{2n})$ as the block matrix
  $$
  J = \left(
  \begin{array}{cc}
    0 & I_n \\
    -I_n & 0
  \end{array}
  \right).
  $$
  A vector field function $f:\R^{2n} \mapsto \R^{2n}$ is said to be
  canonically  Hamiltonian if there exists a scalar smooth function
  $H:\R^{2n} \mapsto \R$ such that 
  \begin{align*}
    \forall u \in \R^{2n}, \quad f(u) = J^{-1} \nabla_u H(u).
  \end{align*}
  A smooth map $(\tau,u) \in \R \times \R^{2n} \mapsto  S_\tau(u) \in
  \R^{2n}$ is said to be symplectic iff
  \begin{align} \label{def:symplectif} %
    \forall u \in \R^{2n}, \quad 
    \left(\partial_u S_\tau(u)\right)^T J \left(\partial_u S_\tau(u)\right) = J,
  \end{align}
  or equivalently
  \begin{align} %
    \forall u \in \R^{2n}, \quad 
    \left(\partial_u S_\tau(u)\right) J^{-1} \left(\partial_u S_\tau(u)\right)^T = J^{-1} .
  \end{align}
\end{definition}
\begin{remark}
  It is known that the $\tau$-flow of a canonically Hamiltonian system is
  symplectic and that the reverse is also true, at least on connected
  sets. This is proved by derivation and use of the integrability Lemma,
  which asserts that a vector function derives from a gradient iff its
  jacobian is symmetric (on a connected set at least).
\end{remark}
\begin{definition}
  A vector field function $f:\R^{n} \mapsto \R^{n}$ is said to be
  divergence free 
  \begin{align*}
    \forall u \in \R^{2n}, \quad \sum_{i=1}^n \partial_i f_i(u) = \Tr(\partial_u f)=0.
  \end{align*}
  A smooth function $(\tau,u) \in \R \times \R^{n} \mapsto  S_\tau(u) \in
  \R^{n}$ is said to be volume-preserving iff
  \begin{align*}
    \forall u \in \R^n, \quad \det\left (\partial_u S_\tau(u)\right)=1.
  \end{align*}
\end{definition}
\begin{remark}
  By differentiation of the determinant, it is straightforward that the
  $\tau$-flow of a divergence-free vector field is volume preserving. The
  converse is true as well. 
\end{remark}
\begin{definition}
  A matrix $B(u) \in {\cal M}(\R^{n})$ is said to be a Poisson matrix if
  it is skew-symmetric and satisfies the Jacobi relation
  $$
  \forall i,j,k \in \{1,\ldots,n\}, \quad \sum_{l=1}^n (\partial_l b_{ij}) b_{lk} +(\partial_l b_{jk}) b_{li}+(\partial_l b_{ki}) b_{lj} = 0. 
  $$
  A vector field function $f:\R^{n} \mapsto \R^{n}$ is said to be Poisson
  if there exists a scalar smooth function $H:\R^{n} \mapsto \R$ and a
  Poisson matrix $B(u)$ such that 
  \begin{align*}
    \forall u \in \R^{n}, \quad f(u) = B(u) \nabla_u H(u).
  \end{align*}
  A smooth function $(\tau,u) \in \R \times \R^{n} \mapsto  S_\tau(u) \in
  \R^{n}$ is said to be a Poisson map  iff
  \begin{align*}
    \forall u \in \R^{n}, \quad \left(\partial_u S_\tau(u)\right) B(u) \left(\partial_u S_\tau(u)\right)^T = B(S_\tau(u)).
  \end{align*}
\end{definition}

\begin{remark} \label{sec:geometry:rmk:equiv_poisson} The $\tau$-flow of a
  Poisson system is a Poisson map symplectic, and the converse is locally
  true if in addition the Casimirs (spanning the null space of $B$) are
  preserved by the flow. This result is found for instance in~\cite[Chap.
  VII, Thm. 4.5]{hairer.2006.geometric}. The proof consists in separating
  the null space and the invertible space of $B$ with a change of
  variable. The invertible space can be treated as in the Hamiltonian
  case, and the null space is preserved by definition of the Casimirs. 
\end{remark}



\subsection{The geometry of stroboscopic averaging}


\begin{theorem} \label{sec:geometry:thm:conservation}
  If $\eps \pa_u F^\eps$ is bounded, then stroboscopic averaging is a
  geometric procedure. More precisely, for $\eps$ small enough, if for all
  $\theta \in \T$, 
  \begin{enumerate}[(i)]
    \item $f_\theta$ is a divergence-free vector field and $X$ is of
    dimension $d < \infty$, then $F^\eps$ is also divergence-free.
    \item the functional $I$ is preserved by the flow of $f_\theta$,
    then it is an invariant of $F^\eps$.
    \item $f_\theta$ is a Hamiltonian vector field, then $F^\eps$ is
    Hamiltonian.
    \item $f_\theta$ is a $B$-Poisson vector field, then $F^\eps$ is
    $B$-Poisson.
  \end{enumerate}
\end{theorem}
\begin{proof}%
%
For the sake of the upcoming proofs, we shall denote for any map $(t,u)
\mapsto \varphi_t(u) \in E$ with $(E, | \cdot |)$ a Banach space, 
at fixed $t$, 
\begin{equation*}
  \| \varphi_t \| = \sup_{u \in X} | \varphi_t(u) | 
  \qquad\text{and}\qquad
  \| \varphi \|_\eps = \sup_{t \leq \eps } \| \varphi_t \| .
\end{equation*}
We also set $C = \sup_\eps \eps \| \pa_u F^\eps \|$. 
%

\medskip\noindent%
\textit{(i)}\indent%
For $(t,u) \in [0,\eps] \times X$, write $R_t(u)$ the deviation from
volume preservation,
\begin{equation*}
  R_t(u) = \det \big( \pa_u \Psi^\eps_t(u) \big) - 1 .
\end{equation*}
Setting $L_t(u) = S_t(u) = \Tr ( \pa_u F^\eps ) \circ \Psi^\eps_t(u)$, it
satisfies
\begin{equation} \label{sec:geometry:eq:ode_R}
  \frac{\dd}{\dd t} R_t = L_t\, R_t + S_t,
  \quad\text{i.e.}\quad
  R_t = \int_0^t L_\tau\, R_\tau \dd \tau 
    + \int_0^t S_\tau \, \dd \tau .
\end{equation}
Taylor's theorem with integral remainder generates the identity 
\begin{equation*}
  R_\eps = R_0 + \eps S_0 + \int_0^\eps (\eps - t) \dot{R}_t \dd t ,
\end{equation*}
which can be simplified thanks the periodicity of~$\Phi^\eps$, as then
$R_\eps = R_0 = 0$. Hence the bound 
\begin{equation*}
  \| S_0 \| \leq \frac{\eps}{2} \| \dot{R} \|_\eps
  \leq \frac{\eps}{2} \left( \| L \|_\eps \, \| R \|_\eps 
    + \| S \|_\eps \right) . 
\end{equation*}
Now applying Gronwall's lemma to the integral form of $R$ yields
$
  \| R_t \| \leq t \|S\|_\eps \, e^{t \|L\|_\eps} , 
$
which injects into the previous bound 
\begin{equation*}
  \| S_0 \| 
    \leq \eps\left( \eps \|L\|_\eps e^{\eps \|L\|_\eps} + 1\right) 
      \| S \|_\eps .
\end{equation*}
Since $S_t = S_0 \circ \Psi_t^\eps$, it appears by one-to-one property of
$\Psi^\eps_t$ that $\|S_0\| = \| S \|_\eps$. The same can be said for $L$,
thus $\eps \| L \|_\eps \leq d C$. We finally obtain 
\begin{equation*}
  \| S \|_\eps \leq \eps \left(1 + d C e^{d C}\right) \| S \|_\eps
\end{equation*}
therefore for $\eps < \left(1 + d C e^{d C}\right)^{-1}$, the source term
in~\eqref{sec:geometry:eq:ode_R} is zero, and the $t$-flow $\Psi^\eps_t$
is volume-preserving. Equivalently, the averaged vector field~$F^\eps$ is
divergence-free. 

%

\medskip\noindent%
\textit{(ii)}\indent%
From the identity 
\begin{equation*}
  \frac{\dd}{\dd t} \left[I \circ \Psi^\eps_t\right] 
  = \left( \pa_u I \cdot F^\eps \right) \circ \Psi^\eps_t , 
\end{equation*}
Taylor's theorem generates 
\begin{equation*}
  I \circ \Psi^\eps_\eps 
  = I + \eps \pa_u I \cdot F^\eps + \int_0^\eps (\eps - t) 
    \left(\pa_u I \cdot F^\eps\right) \circ \Psi^\eps_t \dd t .
\end{equation*}
By periodicity of $\Phi^\eps$, $I \circ \Psi^\eps_\eps = I$, therefore $\|
\pa_u I \cdot F^\eps \| \leq \frac{\eps}{2} \| (\pa_u I \cdot F^\eps)
\circ \Psi^\eps \|_\eps$. By one-to-one property of $\Psi^\eps_t$ at all
$t$, both norms are equal, therefore for $\eps < 2$, 
\begin{equation*}
  \| \pa_u I \cdot F^\eps \| = 0, 
\end{equation*}
i.e. $I$ is an invariant of $F^\eps$. 

%

\medskip\noindent%
\textit{(iii)}\indent%
Writing $R_t$ the deviation from simplecticity, 
\begin{equation*}
  R_t = \pa_u \Psi_t^\eps J^{-1} \left( \pa_u \Psi_t^\eps \right) ^T 
  - J^{-1} ,
\end{equation*}
it satisfies an equation of the form~\eqref{sec:geometry:eq:ode_R} with
$L_t M = \pa_u F^\eps ( \Psi_t^\eps ) M + M \left( \pa_u F^\eps
(\Psi_t^\eps ) \right)^T $ and $S_t = L_t J^{-1}$. 
Exactly the same reasoning can be made as in~\textit{(i)}, therefore the
$t$-flow $\Psi^\eps_t$ is symplectic, i.e. the averaged vector field
$F^\eps$ is Hamiltonian. 

%

\medskip\noindent%
\textit{(iv)}\indent%
This follows from \textit{(ii)} and \textit{(iii)} thanks
to Remark~\ref{sec:geometry:rmk:equiv_poisson}. 

\end{proof}


\todo[inline]{\textbf{TODO~:} Préciser que si une propriété géométrique est
vérifiée par $G$ et $K$ dans le cas autonome, elle est aussi vérifiée dans
le cas filtré. Ça devrait être assez direct vu que $f_\theta$ est la
conjugaison de $K$ par le flot de $G$~: la transformation est assez
géométrique de base.} 


\begin{remark}
  It may be of interest to note that in the linear autonomous case $\pa_t
  u = \frac{1}{\eps} Gu + Ku$, property (i) of volume-preservation does
  not involve the dimension. Indeed differentiating the filtered change of
  variable $\Phi_\theta = e^{-\theta G} e^{\theta G^\eps}$ and taking
  the average yields 
  \begin{equation*}
    G^\eps = \LL \Phi \RR^{-1} G \LL \Phi \RR .
  \end{equation*}
  In the homological equation $\pa_\theta \Omega_\theta = \eps (
  K \Omega_\theta - \Omega_\theta K^\eps )$, we obtain 
  \begin{equation*}
    K^\eps = \LL \Phi \RR^{-1} K \LL \Phi \RR .
  \end{equation*}
  The involvement of the dimension in our proof actually
  seems purely technical, since the averaged vector field $F^\eps$ can be
  expressed as a power series in $\eps$ which converges for $\eps$ small
  enough. Our result shows that every term of the series must be
  divergence-free, but the radius of convergence of the series $\eps_0$ may
  be independent of the dimension of the space.
\end{remark}




\section{Considerations for approximations on bounded domains}
\label{sec:approx}

In this section we discuss what becomes of the previous results in actual
applications, which is to say when the maps $\Phi^\eps$ and $F^\eps$ of
averaging are not known exactly, but only up to error terms of size
$\eps^{n+1}$ for some order $n \in \N$. We also get rid of the assumption
that the vector field $(\theta , u) \mapsto f_\theta(u)$ is uniformly
bounded on the entire space $X$, and conduct our study on a
possibly-bounded open subset~$\mathcal{K} \subset X$. 

\subsection{Assumptions}

For technical purposes, define $\mathcal{K}_\rho$ this subset extended by
a radius of $\rho \geq 0$, i.e.
\begin{equation*}
  \mathcal{K}_\rho = \left\{u \in X \quad \text{s.t.}\quad 
                      \exists\ v \in \mathcal{K}, |u - v| \leq \rho 
                  \right\} .
\end{equation*}
We also define, given a map $\varphi$ from $\mathcal{K}_\rho$ to some
Banach space $(E, |\cdot|)$, the norm 
\begin{equation*}
  \| \varphi \|_\rho = \sup_{u \in \mathcal{K}_\rho} |\varphi(u) |.
\end{equation*}
In particular for the vector fields and morphisms $E = X$, and for their
derivatives $E = \mathcal{L}(E,E)$. 


\begin{assumption} \label{hyp:exist_avg_nl} %
  The vector field $(\theta , u) \mapsto f_\theta(u)$ and its derivative
  are bounded (uniformly w.r.t. $\theta$) on $K_{3R}$ for some radius $R >
  0$. There exist positive constants $\eps_0$ and $C$ such that for
  any rank $n \in \N$, there is a continuous near-identity 1-periodic
  change of variable $\Phi\rk{n}$ and a near-averaged vector field $F\rk
  n$, both well-defined on $\mathcal{K}_{3R}$ for~$\eps \leq \eps_n :=
  \eps_0 / (n+1)$. Precisely,
  \begin{equation*}
    \sup_{\theta \in \T} \| \Phi\rk n_\theta - \id \| _{3R} 
      \leq \frac{\eps}{\eps_n} R
    \qquad\text{and}\qquad
    \| F\rk n \|_{3R} \leq C .
  \end{equation*}
  Furthermore, the error of approximation is of size $\eps^{n+1}$, i.e.
  writing $\Psi\rk n _t$ the $t$-flow of $F\rk n$, 
  \begin{equation} \label{sec:approx:def:avg_approx}
    u(t) = \Phi\rk n _{t/\eps} \circ \Psi\rk n _t \circ \big( \Phi\rk n _0
    \big)^{-1} (u_0) + \bigO(\eps^{n+1}) 
  \end{equation}
  until some time $T_R > 0$. 
\end{assumption}
The error of approximation is caracterised by the defect $\delta\rk n$
defined by 
\begin{equation*} 
  \delta\rk n _{\theta} 
  = \frac{1}{\eps} \pa_\theta \Phi\rk n _\theta
    - f_\theta \circ \Phi\rk n _\theta 
    + \pa_u \Phi\rk n _\theta \cdot F\rk n , 
\end{equation*}
which corresponds to the error in the homological
equation~\eqref{sec:presentation:eq:homol}. The previous assumptions
corresponds to the situation
\begin{equation} \label{sec:approx:hyp:delta}
  \sup_{\theta \in \T} \| \delta\rk n \| _{3R} = \bigO( \eps^n )
  \qquad\text{and}\qquad
  \LL \delta\rk n \RR = \bigO( \eps^{n+1} ) .
\end{equation}
%
This assumption matches the behaviour generally observed with averaging,
found for instance in~\cite{castella.2015.stroboscopic} when assuming
$(\theta,u) \mapsto f_\theta(u)$ analytic w.r.t. $u$. As noted
in~\cite{chartier.2015.higher}, this is enough to ensure the historical
optimal ``exponential'' error bound of~\cite{neishtadt.1984.separation},
which can be stated as such: There is a positive constant $c$ such that for
all $\eps > 0$ there is an integer $n$ such that for all $t$,
\begin{equation*}
  \left| u(t) - \Phi\rk n _{t/\eps} \circ \Psi\rk n_t 
  \circ \big( \Phi\rk n _0 \big)^{-1} (u_0) \right| 
  \leq c e^{-c/\eps} .
\end{equation*}
This reflects the fact that the maps $\Phi^\eps$ and $F^\eps$ can only be
obtained as diverging power series in $\eps$, therefore the error is
\textit{formal}, up to a flat function. Indeed, in order to increase the
order of the approximation, $\eps$ must get smaller and smaller, such that
an error $\bigO( \eps^\infty )$ is impossible with $\eps \neq 0$. 

%

Note furthermore that this assumption is enough to ensure that $\Phi\rk n
_0$ and $\LL \Phi\rk n \RR$ are invertible from $\mathcal{K}_\rho$ to
$\mathcal{K}_{\rho + R}$ for any $\rho \in [0, 3R]$. Indeed for $u \in
\mathcal{K}_\rho$, the map $\varphi(v) = u + v - \Phi\rk n _0(u+v)$ maps
the closed ball of radius $R$ onto itself,\footnote{%
If $\eps \leq \alpha \eps_n$ for $\alpha \in (0,1]$, then this
radius becomes $\alpha R$, therefore $\Phi\rk n _0$ injects
$\mathcal{K}_\rho$ into $\mathcal{K}_{\rho + \alpha R}$. } %
thus admits a fixed point by Brouwer's fixed point theorem. Therefore
there exists $u^* = u + v^* \in \mathcal{K}_{\rho + R}$ such that $u =
\Phi\rk n _0 (u^*)$. The same reasoning holds for $\LL \Phi\rk n \RR$. 


\subsection{Autonomous case}

Consider the autonomous problem~\eqref{sec:autonomous:eq:pb_v} of
Section~\ref{sec:autonomous}, 
\begin{equation*}
  \dot v^\eps = \frac{1}{\eps}G(v^\eps) + K(v^\eps),
  \qquad
  v^\eps(0) = v_0 .
\end{equation*}
The flow of $G$, denoted $(\theta,u) \mapsto \chi_\theta(u)$, is assumed
1-periodic w.r.t. $\theta$, and we assume that for every radius $\rho$,
the set $\mathcal{K}_\rho$ is invariant by the flow of $G$. Performing
averaging on this problem is equivalent to performing it on the filtered
problem 
\begin{equation*}
  \dot u^\eps(t) = \big( \pa_u \chi_{-t/\eps} \cdot K \big) 
    \circ \chi_{t/\eps} (u^\eps(t)),
  \qquad
  u^\eps(0) = v_0 .
\end{equation*}
The unfiltered variable is obtained as $v^\eps(t) =
\chi_{t/\eps}(u^\eps(t) )$. Given an approximation $v^\eps(t) = \Omega\rk
n _{t/\eps} \circ \Psi\rk n _t \circ \big( \Omega\rk n _0 \big)^{-1} +
\bigO(\eps^{n+1} )$, an approximation on~$u^\eps$ of the
form~\eqref{sec:approx:def:avg_approx} is obtained by setting $\Phi\rk n
_\theta = \chi_{-\theta} \circ \Omega\rk n _\theta$. Conversely, it is
also possible to obtain $\Omega\rk n$ from working on the filtered
problem, and in the case where $u \mapsto G(u)$ is non-linear, this latter
approach is generally more straightforward. The defect associated to 
averaging on the autonomous problem is 
\begin{equation} \label{sec:approx:def:eta}
  \eta\rk{n}_{\theta} 
  := \frac{1}{\eps} \left( \pa_\theta \Omega\rk n _\theta 
  - G \circ \Omega\rk n _\theta \right) 
  - K \circ \Omega\rk n _\theta + \pa_u \Omega\rk n _\theta K\rk n 
\end{equation}
and the link is made with the filtered averaging with the formula 
\begin{equation*}
  \eta\rk n _\theta = \pa_u \chi _\theta \big( \Phi\rk n _\theta \big)
  \cdot \delta\rk n _\theta .
\end{equation*}



\begin{theorem}[Adaptation of
Propositions~\ref{sec:autonomous:prop:phigroup} 
and~\ref{sec:autonomous:prop:commut}] \hspace*{1em} 
\\
  Given averaging maps $\Phi\rk n$ and $K\rk n$ which satisfy
  Assumption~\ref{hyp:exist_avg_nl} (with $F\rk n$ replaced by $K\rk n$)
  and such that the associated defect $\delta\rk n$
  satisfies~\eqref{sec:approx:hyp:delta}, define the change of variable
  $(\theta, u) \mapsto \Omega\rk n _\theta(u) = \chi _{-\theta} \circ
  \Phi\rk n _\theta(u)$ for autonomous averaging. With this definition,
  $\Omega\rk n _\theta$ is the $\theta$-flow of a vector field $G\rk n$
  defined on $\mathcal{K}_R$ up to $\bigO(\eps^{n+2})$. Furthermore, $G\rk
  n$ and $K\rk n$ commute up to $\bigO(\eps^{n+2})$ on $\mathcal{K}_{R}$. 
\end{theorem}

\begin{proof}
The first step of the proof is to show 
\begin{equation*}
  K\rk n = \mathcal{A}^{\theta_1}[ \Omega\rk n ] + \bigO( \eps^{n+1} )
\end{equation*}
for all phases $\theta_1 \in \T$, with $\mathcal{A}^{\theta_1}$ the
operator defined in~\eqref{sec:autonomous:def:avg_op}. This result stems
from the identity on $\widetilde{\Phi}\rk n _\theta = \chi_{-\theta -
\theta_1} \circ \Omega\rk n _\theta$, 
\begin{equation*}
  \pa_\theta \widetilde{\Phi}\rk n _\theta 
  = \eps \big( f_{\theta+\theta_1} \circ \widetilde{\Phi}\rk n _\theta
    - \pa_u \widetilde{\Phi}\rk n _\theta \cdot K\rk n 
  \big)
  - \eps \pa_u \chi_{-\theta - \theta_1}(\Omega\rk n _\theta) 
    \cdot \eta\rk n _\theta .
\end{equation*}
Before taking the average, compute
\begin{align*}
  \pa_u \chi_{-\theta - \theta_1}(\Omega\rk n _\theta) 
    \cdot \eta\rk n _\theta = &\ 
  \pa_u \chi_{-\theta-\theta_1} \big( \chi_\theta \Phi\rk n _\theta \big)
  \pa_u \chi_\theta (\Phi\rk n _\theta) \delta\rk n _\theta
  \\ = &\ 
  \pa_u ( \chi_{-\theta-\theta_1} \circ \chi_\theta 
    \circ \Phi\rk n _\theta)
  \big( \pa_u \Phi\rk n _\theta \big)^{-1} \delta\rk n _\theta
  \\ = &\ 
  \pa_u \chi_{-\theta_1} (\Phi\rk n _\theta) \delta\rk n _\theta
\end{align*}
Hence this term can be written as $\pa_u \chi_{-\theta_1} \big( \id +
\bigO(\eps) \big) \delta\rk n _\theta$, and its average is of size
$\bigO( \eps^{n+1} )$ thanks to the assumption on $\delta\rk n$. Taking
the average of the previous identity, we finally obtain 
\begin{equation*}
  K\rk n = \mathcal{A}^{\theta_1} [\Omega\rk n] + \bigO( \eps^{n+1} ) .
\end{equation*}


We then proceed in the same manner as for the proof of
Proposition~\ref{sec:autonomous:prop:phigroup}. For some phase $\theta_0
\in \T$, consider the map $\widetilde{\Omega}\rk n _\theta = \Omega\rk n
_{\theta + \theta_0} \circ \big( \Omega\rk n _{\theta_0} \big) ^{-1}$
defined on $\mathcal{K}_R$. By definition of the defect, this new map
satisfies the equation, 
\begin{equation*} 
  \partial_\theta \widetilde\Omega\rk n _{\theta}
  - G \circ \widetilde \Omega\rk n _{\theta}
  = \eps\left( K \circ \widetilde \Omega\rk n _{\theta}
    - \partial_u \widetilde \Omega\rk n _{\theta} \cdot 
    \widetilde{K}\rk n
  \right) 
  - \eps \widetilde{\eta}\rk n _\theta  .
\end{equation*}
with $\widetilde{K}\rk n = \big(\partial_u (\Omega\rk n _{\theta_0})^{-1}
\big)^{-1} \cdot K\rk n  \circ (\Omega\rk n _{\theta_0})^{-1}$ and $
\widetilde{\eta}\rk n _\theta = \eta\rk n _{\theta + \theta_0} \circ
(\Omega\rk n _{\theta_0} ) ^{-1}$. From~\eqref{sec:approx:def:eta}, it
appears in particular that $K\rk n = \mathcal{A}^{\theta_0}[\Omega\rk n] +
\bigO(\eps^{n+1} \big)$. Injected into $\widetilde{K}\rk n$, this
generates 
\begin{equation*}
  \widetilde{K}\rk n = 
  \Big( \pa_u \bLL \chi_{-\theta} 
    \circ \widetilde\Omega^\eps _\theta \bRR \Big) ^{-1}
  \BLL (\pa_u \chi_{-\theta} \cdot K) 
    \circ \widetilde\Omega^\eps _\theta \BRR + \bigO( \eps^{n+1} ) 
  = \mathcal{A}^{0}[\widetilde{\Omega}^\eps] + \bigO( \eps^{n+1} ) . 
\end{equation*}
Hence $\Omega\rk n$ and $\widetilde{\Omega}\rk n$ satisfy the same
equation up to a modification of the defect while still
respecting~\eqref{sec:approx:hyp:delta}. In other words, we can replace
$\Omega\rk n$ by $\widetilde{\Omega}\rk n$ in the following equation 
\begin{equation*}
  \partial_\theta \Omega\rk n _{\theta}
  - G \circ  \Omega\rk n _{\theta}
  = \eps\left( K \circ  \Omega\rk n _{\theta}
    - \partial_u  \Omega\rk n _{\theta} \cdot 
    \mathcal{A}^0[\Omega\rk n]
  \right) + \bigO( \eps^{n+1}) 
\end{equation*}
without impacting the result. Since these two maps satisfy the same
closure condition $\Omega\rk n _0 = \id + \bigO( \eps^{n+1} )$, they
differ by only $\bigO( \eps^{n+1})$ at any phase $\theta \in \T$. We can
finally define 
\begin{equation*}
  G\rk n = \pa_\theta \Omega\rk n _\theta \big|_{\theta = 0} .
\end{equation*}
The second part of the theorem stems from the identity $K\rk n =
\widetilde{K}\rk n + \bigO( \eps^{n+1} )$ which becomes 
\begin{equation*}
  K\rk n \circ \Omega\rk n _{\theta_0} 
  = \pa_u \Omega\rk n _{\theta_0} \cdot K\rk n + \bigO ( \eps^{n+1} ) . 
\end{equation*}
\end{proof}

Note that the exact flow of $G\rk n$ may not be 1-periodic depending on
its definition. Think for instance of the one-dimensional converging
example $G\rk n = i(1-\eps) \sum_{k = 0}^{n} \eps^k = i( 1 - \eps^{n+1}
)$. 


\subsection{Geometric properties}
Here is what the preservation of geometric properties presented in
Section~\ref{sec:geometry} becomes. 

\begin{theorem}[Adaptation of Theorem~\ref{sec:geometry:thm:conservation}]
\hspace*{1em} \\
  Consider Assumption~\ref{hyp:exist_avg_nl} met and denote $\varphi^\eps
  _t$ the $t$-flow associated to Problem~\eqref{sec:intro:eq:ode_u}. Up to
  a reduction of~$\eps_0$, the following properties are satisfied up to an
  error of size $\bigO(\eps^{n+1})$~: if for all $t \in [0, T_R]$, 
  \begin{enumerate}[(i)]
    \item $u \mapsto \varphi^\eps _t(u)$ is volume-preserving on $\mathcal{2R}$, then
    $\Psi\rk n _t$ is volume-preserving on $\mathcal{K}_R$~;
    \item the functional $I$ is preserved by $\varphi^\eps _t$ on
    $K_{2R}$, then it is preserved by $\Psi\rk n _t$ on
    $\mathcal{K}_R$~; 
    \item $\varphi^\eps _t$ is symplectic on $\mathcal{K}_{2R}$, then
    $\Psi\rk n _t$ is symplectic on $\mathcal{K}_R$~;
    \item $\varphi^\eps _t$ is $B$-symplectic and preserves Casimirs on
    $\mathcal{K}_{2R}$, then $\Psi\rk n _t$ also does on $\mathcal{K}_R$.
  \end{enumerate}
  Note that since $\Phi\rk n _\theta = \varphi^\eps _{\eps\theta} \circ
  \Psi\rk n _{\eps\theta} + \bigO(\eps^{n+1})$, these properties are also
  true for $\Phi\rk n _\theta$. It is therefore possible to modify $\Phi\rk
  n$ and $F\rk n$ and have these properties met exactly, altough the
  impact of this process on the well-posedness of the maps is unclear.
\end{theorem}

\begin{proof}
As can be seen in the proof of
Theorem~\ref{sec:geometry:thm:conservation}, every property can be proven
in the same way. Therefore we will only describe how to
prove~\textit{(iii)}, as it is probably the most interesting property for
the majority of readers. We refer to the other proof for the adaptation to
other properties. 

Set $(t,u) \mapsto \Delta_t(u)$ the deviation from symplecticity, 
\begin{equation*}
  \Delta_t = \big(\pa_u \Psi_t\rk n\big) J^{-1} 
      \big( \pa_u \Psi_t\rk n \big) ^T 
    - J^{-1} ,
\end{equation*}
defined and bounded for $u \in \mathcal{K}_{R_n}$ 
Thanks the periodicity of~$\Phi\rk n$, $t \mapsto \Delta_t$ is almost zero at
stroboscopic times, meaning that for all $k \in \N$ such that $\eps k \leq
T_R$, since $\Psi\rk n _{\eps k} = \varphi^\eps _{\eps k} + \bigO(
\eps^{n+1})$,
\begin{equation*}
  \Delta_{\eps k} 
  = \big(\pa_u \varphi ^\eps _{\eps k}\big) J^{-1} 
      \big( \pa_u \varphi^\eps _{\eps k} \big) ^T 
    - J^{-1} + \bigO( \eps^{n+1} )
  = \bigO( \eps^{n+1} ) .
\end{equation*}
Setting $L_t M = \pa_u F\rk n ( \Psi_t\rk n ) M + M \big( \pa_u F\rk n
(\Psi_t\rk n ) \big)^T $ and $S_t = L_t J^{-1}$, it satisfies
\begin{equation} \label{sec:approx:eq:ode_R}
  \pa_u \Delta_t = L_t\, \Delta_t + S_t,
  \quad\text{i.e.}\quad
  \Delta_t = \Delta_0 + \int_0^t L_\tau\, \Delta_\tau \dd \tau 
    + \int_0^t S_\tau \, \dd \tau .
\end{equation}
We want to prove $\sup_{0 \leq t \leq \eps} \| \Delta_t \|_R = \bigO(\eps^{n+1}
)$. To that effect, introduce the norm~$\|\cdot\|_{\eps, \rho}$ and the
radii~$R_k$, 
\begin{equation*}
  \| g \|_{\eps, \rho} = \sup_{0 \leq t \leq \eps} \| g_{t} \|_{\rho}
  \qquad\text{and}\qquad
  R_k = R + \frac{k}{n+1}R ,
\end{equation*}
and set $\alpha > 0$ such that $\| \Delta_0 \|_{2R}, \| \Delta_\eps
\|_{2R} \leq \alpha \eps^{n+1}$. Gronwall's lemma in the integral form of
$\Delta_t$ yields 
\begin{equation} \label{sec:approx:eq:gronwall}
  \| \Delta \|_{\eps, R} 
  \leq \big( \alpha \eps^{n+1} + \eps \| S \|_{\eps, R} \big)
    e^{\eps \| L \|_{\eps, R}} ,
\end{equation}
therefore we want to show $\| S \|_{\eps, R} = \bigO( \eps^{n+1} )$.
Because $S$ is transported by $F\rk n$, i.e. $S_t = S_0 \circ \Psi\rk n
_t$, it is possible to bound $S_t$ on some space $\mathcal{K}_\rho$ by the
norm of $S_0$ on a larger space. In particular, assuming $\eps_0 \leq
R/C$, 
\begin{equation} \label{sec:approx:eq:transported_bound}
  \| S \|_{\eps, R_k} \leq \| S_0 \| _{R_{k+1}}
\end{equation}
since $\| \Psi\rk n _t - \id \|_{R_n} \leq t C $. This bound is fairly
useful, as Taylor's theorem with integral remainder generates the identity
\begin{equation*} \label{sec:approx:eq:taylor}
  \Delta_\eps = \Delta_0 + \eps S 
    + \int_0^\eps (\eps - t) \, \pa_t \Delta _t \dd t ,
\end{equation*}
from which a Cauchy inequality yields 
\begin{equation*}
  \| S_0 \|_{R_1} 
  \leq \frac{\eps}{2} \| \pa_t \Delta \|_{\eps, R_1} 
    + 2 \alpha \eps^{n}
  \leq \frac{\eps}{2} \left( \| L \|_{\eps, R_1} \, \| \Delta \|_{\eps, R_1} 
    + \| S \|_{\eps, R_1} \right) + 2\alpha\eps^{n} . 
\end{equation*}
Injecting~\eqref{sec:approx:eq:gronwall}
and~\eqref{sec:approx:eq:transported_bound} into the right-hand term, we
obtain 
\begin{equation*}
  \| S_0 \|_{R_1} 
  \leq \frac{\eps}{2} (1 + C_L) \| S_0 \|_{R_2}
    + ( 2 + \eps C_L ) \alpha \eps^{n} .
\end{equation*} 
where $C_L = \eps \| L_0 \|_{2R} e^{\eps \| L_0 \|_{2R}}$ (exploiting the
fact that $L$ is transported by $F\rk n$). We set $\kappa = \frac{1}{2}( 1
+ C_L)$ and $q = \alpha (2 + \eps C_L)$ for brevity, and successive
applications of this reasoning on $\| S_0 \|_{R_k}$ generate 
\begin{equation*}
  \| S_0 \| _{R_1} 
  \leq (\eps \kappa)^n \| S_0 \|_{2R}
    + \sum_{k = 0}^{n-1} (\eps \kappa) q \eps^n
  \leq \left(\frac{\eps}{2\eps_0}\right)^n \| S_0 \|_{2R} 
    + 2q \eps^n
\end{equation*}
assuming $\eps_0 \leq 1/(2\kappa)$. Finally, $\| S_0 \|_{R_1} =
\bigO(\eps^{n+1})$ thus $\| \Delta \|_{\eps, R} = \bigO( \eps^{n+1} )$.
This reasoning can be conducted on any time interval of the form $[\eps k,
\eps (k+1)]$, proving that $R$ is of size $\big( \eps^{n+1})$ at all
times. 

\end{proof}