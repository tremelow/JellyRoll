\section*{Application de méthodes numériques générales}
\addcontentsline{toc}{section}{Application de méthodes numériques générales}

On cherche à résoudre le problème~\eqref{sec:intro:eq:u} numériquement.
Dans un premier temps, il faut présenter comment les méthodes de
résolution standards se comportent lorsqu'on les adapte au problème en
question. Par \enquote{méthodes standards}, on entend des méthodes
enseignées en études supérieures, et qui peuvent être trouvées dans les
livres de référence \textbf{REF}\todo{Hairer Wanner 1 \& 2 + GNI}. Il
s'agit de méthodes de résolution pour des équations différentielles
ordinaires quelconques, qui ne prennent pas en compte la structure
spécifique du problème. 


Il est difficile de traiter le continu d'un point de vue numérique, donc
on commence d'abord par \textit{discrétiser} l'intervalle de temps en un
nombre arbitraire $N \in \setN^*$ d'intervalles.
%
\todo[inline]{Dessin avec la définition des $t_n$ (voir commentaire)
    % |-----|-----|---//---|-----|
    % 0     Dt   2Dt      T-Dt   T
}
\todo[inline]{Notion d'ordre et de solution}
%
\noindent%
Pour des raisons pratiques, les mathématiciens aiment diviser
l'intervalle de temps de manière uniforme comme sur le schéma ci-dessus.
Néanmoins, une autre approche qui semble plus efficace serait de placer
les points de discrétisation $(t_n)$ de manière uniforme le long de la
courbe solution 
%
\todo[inline]{Figure pour le pas de temps adaptatif avec l'interprétation de distance uniforme sur la courbe (préciser que c'est une simplification, vu qu'avec un système affine on peut prendre le pas qu'on veut)}
%
\noindent%
Dans les faits, on ne placerait pas les points avec une répartition
uniforme sur la courbe, mais avec une répartition uniforme sur la courbe
de sa dérivée à un certain ordre lié à l'ordre du
schéma.\todo{définition ordre avant??}


Dans la suite de cette section, on restreint notre étude du comportement
de certaines méthodes appliquées au problème particulier
\begin{equation} \label{sec:intro:eq:pb_ztest}
    \pa_t z(t) = -\frac{1}{\eps}z(t) + \cos(t),
    \qquad z(0) = 1 .
\end{equation}
Ce problème est un cas particulier de~\eqref{sec:intro:eq:xz} avec
$a(x,z) = 1$ et $b(x,z) = \cos(x)$. Une condition initiale $x(0) = 0$
permet d'assimiler $x$ à la variable de temps $t$ pour obtenir le
problème ci-dessus. On en connaît la solution exacte 
\begin{equation*}
    z(t) = e^{-t/\eps} \left( z(0) - \frac{\eps}{1+\eps^2} \right)
        + \frac{\eps}{1 + \eps^2} \big( \cos(t) + \eps \sin(t) \big) .
\end{equation*}

\todo[inline]{Dire que c'est comme résoudre un problème non-raide en temps long}





\subsection*{Application directe de schémas standards}
\addcontentsline{toc}{subsection}{Application directe de schémas standards}


On cherche à résoudre le problème~\eqref{sec:intro:eq:u} numériquement.
En termes simples, cela veut dire trouver une méthode générale pour
obtenir la solution du problème. On va montrer que les méthodes
\enquote{standards} sont inefficaces pour résoudre même le problème
simplifié 
\begin{equation} \label{sec:intro:eq:pb_zlin}
    \pa_t z = -\frac{1}{\eps}z
\end{equation}
avec une donnée initiale $z(0) \in \setR$ quelconque. Par
\enquote{méthodes standards}, on entend des méthodes qui peuvent être
trouvées dans le livre de référence \textbf{REF}\todo{Hairer Wanner 1}.
Il s'agit de méthodes de résolution pour des équations différentielles
ordinaires quelconques, qui ne prennent pas en compte la structure
spécifique du problème qui nous intéresse. 


Il est difficile de traiter le continu d'un point de vue numérique, donc
on commence d'abord par \textit{discrétiser} l'intervalle de temps en un
nombre arbitraire $N \in \setN^*$ d'intervalles.
%
\todo[inline]{Dessin avec la définition des $t_n$ (voir commentaire)
    % |-----|-----|---//---|-----|
    % 0     Dt   2Dt      T-Dt   T
}
%
\noindent%
Pour le moment, on choisit de se restreindre à une discrétisation
uniforme, c'est-à-dire que l'intervalle de temps $[0,T]$ est divisé en
$N$ intervalles de taille égale. De manière équivalente, on définit les
points de séparation $(t_n)_{0 \leq n \leq N}$ avec 
\begin{equation*}
    t_n = \frac{n}{N} T ,
\end{equation*}
ou encore 
\begin{equation*}
    t_{n+1} = t_n + \Dt
    \qquad\text{avec}\qquad
    t_0 = 0 \quad\text{et}\quad \Dt = \frac{T}{N} .
\end{equation*}

L'idée est maintenant d'obtenir une approximation de~$u_n \approx
u^\eps(t_n)$ en chaque point. La méthode la plus directe est la méthode
d'Euler~: On a accès à la valeur initiale $u_0$, et on peut ensuite
calculer le prochain point par projection 
%
\todo[inline]{\textbf{Graphique :} Tracer la droite qui part de $z_n$
avec la pente $-z_n/\eps$ pour placer le point $z_{n+1}$.}
%
\noindent%
On obtient ainsi la \textit{suite d'Euler} du
problème~\eqref{sec:intro:eq:pb_zlin}~:
\begin{equation} \label{sec:intro:eq:euler}
    z_{n+1} = \left( 1 - \frac{\Dt}{\eps} \right) z_n , 
    \qquad
    z_0 = z(0) .
\end{equation}
D'autres méthodes de projection existent, notamment les méthodes de
Runge-Kutta qui impliquent des points intermédiaires, ou les méthodes
multi-points qui utilisent les valeurs en $n, n+1, \ldots, n+s$ pour
calculer le point en $n+s+1$. Le raisonnement qui suit s'applique (à une
constante près) à toutes ces méthodes de calcul tant qu'elles sont
\textit{explicites}. Le schéma numérique est dit \textit{stable} si la
norme de la solution calculée ne croît pas,\footnote{%
Cette définition atteint vite sa limite lorsqu'on considère des
problèmes à solution croissante, par exemple $\pa_t x = x$.
Heureusement, ce n'est pas le cas ici.} i.e. si 
\begin{equation*}
    \left|\, 1 - \frac{\Dt}{\eps} \,\right| \leq 1 .
\end{equation*}
Cette condition est généralement interprété comme une restriction sur le
pas de temps $\Dt$. Néanmoins, nous sommes aussi intéressés par le
comportement du schéma par rapport à la variable de raideur $\eps$. En
considérant $\Dt$ fixé, il est clair qu'il faut prendre $\Dt$ plus petit
que $\eps$ pour avoir une solution décroissante. Le coût de calcul dans
la limite $\eps \rightarrow 0$ évolue ainsi au moins en $\bigO(1/\eps)$.

Vérifions que cette condition se remarque aussi sur l'erreur. On pose
$\tau_n$ l'erreur dite de troncature du schéma entre $t_n$ et $t_{n+1}$,
\begin{equation*}
    \tau_n = z(t_{n+1}) - z(t_n) - \Dt \pa_t z(t_{n}) .
\end{equation*}
On applique la formule de Taylor avec reste intégral entre $t_n$ et
$t_{n+1}$, d'où 
\begin{equation*}
    \tau_n = \int_{t_n}^{t_{n+1}} (t_{n+1} - t) 
        \pa_t^{\:2}z(t) \dd t ,
\end{equation*}
et on peut borner cette erreur à l'aide d'une inégalité de Hölder,
\begin{equation*}
    |\tau_n| \leq \Dt 
        \int_{t_n}^{t_{n+1}} \left| \pa_t^{\:2} z(t) \right| \dd t .
\end{equation*}
On remarque ensuite 
\begin{equation*}
    z_{n+1} - z(t_{n+1}) 
    = \left(1 - \frac{\Dt}{\eps}\right)(z_n - z(t_n))
        - \tau_n
\end{equation*}
d'où, de proche en proche, et comme $z_0 = z(0)$,
\begin{equation*}
    z_{n+1} - z(t_{n+1}) 
    = -\sum_{k = 0}^n \left(1 - \frac{\Dt}{\eps}\right)^k \tau_{n-k} .
\end{equation*}
Encore par inégalité de Hölder (discrète, cette fois-ci), on obtient
\begin{equation*}
    \left| z_{n+1} - z(t_{n+1}) \right|
    \leq \sum_{k = 0}^n |\tau_k| \leq \Dt \| \pa_t^{\:2}z \|_{L^1}
\end{equation*}
avec la norme $L^1$ définie de manière canonique, c'est-à-dire $ \| u
\|_{L^1} \leq \int_0^T | u(t) | \dd t $. 

En fait, cette dernière
inégalité est vraie quel que soit le problème résolu (i.e. même si on
modifie l'équation sur $z$), tant que la condition de stabilité (à
adapter au problème) est vérifiée. En particulier, cela veut dire qu'on
obtient la même borne d'erreur si on utilise la méthode d'Euler sur le
problème plus complexe~\eqref{sec:intro:eq:u}. 

Dans le cas simplifié $\pa_t z = -z/\eps$, on connaît la solution
exacte du problème, et on peut calculer $\| \pa_t^{\:2}z \|_{L^1} =
\frac{1}{\eps} (1 - e^{-T/\eps}) |z_0|$. Ainsi, la borne d'erreur
devient pour tout indice $n$ entre $0$ et $N$,
\begin{equation*}
    \left| z_n - z(t_n) \right| \leq \frac{\Dt}{\eps} |z_0| .
\end{equation*}
Il apparaît très clairement que le paramètre à ajuster pour modifier
l'erreur est $\Dt/\eps$, pas juste $\Dt$. On aurait pu espérer qu'en
fixant ce rapport avec $\Dt = \eps$, l'erreur tende vers zéro dans la
limite $\eps \rightarrow 0$, mais ce n'est même pas le cas ici. 

On aurait ainsi l'impression que pour obtenir une erreur de taille
$\eps$, il faudrait choisir $\Dt = \eps \delta$. Heureusement on peut
exploiter la borne
\begin{equation*}
    \left| z_n - z(t_n) \right| \leq \sum_{k \geq 0} |\tau_k| 
\end{equation*}
pour essayer de répartir presque uniformément l'erreur entre les
$\tau_n$ en modulant le pas de temps à chaque itération. Ainsi, on
remplacerait le schéma~\eqref{sec:intro:eq:euler} par 
\begin{equation*}
    z_{n+1} = z_n - \frac{\Dt_n}{\eps} z_n
\end{equation*}
avec $\Dt_n$ qui varie en fonction de l'itération. La
formule~\eqref{sec:intro:eq:euler_err1} reste valide en remplaçant $\Dt$
par $\Dt_n$, et c'est ça qu'on souhaite exploiter. Notamment, on peut
séparer l'intervalle de temps en deux parties~: pendant la phase
transitoire (pas de temps $\Dt_0$) et après la phase transitoire (pas de
temps $\Dt_1$). Ici, on détermine la fin de la phase transitoire au
temps $t_f$ tel que $\pa_t^{\:2} z(t_f) = \bigO(1)$, soit $t_f = -\eps
\log(\eps)$ en supposant $\eps < 1$. 

En posant $z_0 = 1$ pour simplifier, supposons qu'on souhaite avoir une
erreur de $\delta/2$ à la fin de la période transitoire. Cela se traduit
en 
\begin{equation*}
    \Dt_0 \int_0^{t_f} |\pa_t^{\:2} z(t)| \dd t 
    \leq \Dt_0 \frac{1 - \eps}{\eps} \leq \frac{\delta}{2} .
\end{equation*}
Ainsi on choisit $\displaystyle \Dt_0 = \frac{\eps \delta}{2(1 -
\eps)}$. L'erreur après la phase transitoire est 
\begin{equation*}
    \Dt_1 \int_{t_f}^{T} |\pa_t^{\:2} z(t)| \dd t 
    \leq \Dt_1 ,
\end{equation*}
donc si on souhaite avoir une erreur $\delta/2$ lors de cette seconde
phase, on peut poser $\Dt_1 = \min(\eps, \delta/2)$ de sorte à être
certain de respecter la condition de stabilité. Le coût associé à la
phase transitoire est 
\begin{equation*}
    \frac{t_f}{\Dt_0} = \frac{2 (1-\eps) \log(1/\eps)}{\delta} ,
\end{equation*}
et celui associé à la période qui suit est $\displaystyle \frac{ T -
\eps \log(1/\eps)}{\min(\eps, \delta/2)}$. Ce coût est largement
préférable au coût en $1/(\eps \delta)$ qu'on aurait trouvé avec un pas
de temps uniforme, mais il reste en $\bigO(1/\eps)$ quand $\eps
\rightarrow 0$ à $\delta$ fixé à cause de la condition de stabilité.

\todo[inline]{Parler de méthodes de Chebichev (grand domaine de 
stabilité) + des estimations d'erreur}




\subsection*{Méthodes implicites}
\addcontentsline{toc}{subsection}{Méthodes implicites}

Un moyen généralement invoqué pour stabiliser les problèmes raides comme
celui-ci est l'utilisation de schémas \textit{implicites}. Je n'ai pas
étudié ces méthodes en détail, mais elles méritent d'être mentionnées et
leur non-étude demande justification. On présente ici rapidement la
méthode d'Euler implicite, ainsi que d'autres méthodes adaptées aux
problèmes raides compilées dans \textbf{REF}\todo{Hairer et al 2}. On
discute enfin de leurs limites.


Pour la méthode d'Euler implicite, au lieu de faire une projection
directe (dans la méthode explicite), on cherche le point qui, en temps
rétrograde, aurait donné le point précédent.
%
\todo[inline]{Schéma avec différentes lignes de niveau et les tangentes
qui partent de différents $u_{n+1}$ possibles}
%
\noindent%
Cette méthode de projection rétrograde \enquote{directe} est appelée
méthode d'Euleur implicite, et le schéma associé dans le cas du
problème~\eqref{sec:intro:eq:pb_zlin} est 
\begin{equation*}
    z_{n+1} = z_n - \frac{\Dt}{\eps} z_{n+1} ,
\end{equation*}
ou encore 
\begin{equation*}
    z_{n+1} = \frac{\eps}{\Dt + \eps} z_n .
\end{equation*}
En comparant les figures~\textbf{REF}\todo{Labels}, il est clair que
cette méthode est en général bien plus coûteuse que les méthodes
explicites de projection directe. Néanmoins, elle présente quelques
propriétés sympathiques que nous devons présenter. Ce schéma est
clairement stable pour tout $\Dt$ et tout $\eps$, puisque le facteur
multiplicatif est toujours inférieur à $1$. Cependant, cela n'indique
rien sur l'erreur associée au schéma. Calculons-la rapidement.

On pose $\tau_n$ l'erreur dite de troncature du schéma entre $t_n$ et
$t_{n+1}$,
\begin{equation*}
    \tau_n = z(t_{n+1}) - z(t_n) - \Dt \pa_t z(t_{n+1}) .
\end{equation*}
% Par théoréme fondamental de l'analyse, $\tau_n = \int_0^{\Dt} \big(
% \pa_t z(t_n + s) - \pa_t z(t_{n+1}) \big) \dd s$, d'où, avec une
% application supplémentaire de la formule,
% \begin{equation*}
%     \tau_n = \int_0^{\Dt} \int_s^{\Dt} 
%         \pa_t^{\:2} z(t_n + \mu) \dd \mu \dd s
% \end{equation*}
% On remarque qu'il s'agit d'une intégrale sur le triangle~:
% \todo[inline]{Figure du triangle (voir commentaire)
% % (0,h)  ----------- (h,h)
% %        |        /
% %  mu    |      /
% %        |    /
% %        |  /
% % (0,0)  |/
% %            s
% }
% On peut donc inverser les intégrales et obtenir
% \begin{equation*}
%     \tau_n = \int_0^{\Dt} \int_0^{\mu} 
%         \pa_t^{\:2} z(t_n + \mu) \dd s \dd \mu .
% \end{equation*}
% d'où la borne par inégalité triangulaire 
En général on borne cette erreur par une application successive
d'intégration par parties, inégalité triangulaire et enfin inégalité de
Hölder, pour trouver
\begin{equation} \label{sec:intro:eq:euler_err1}
    \left| \tau_n \right| 
    \leq \int_0^{\Dt} s \left| \pa_t^{\:2} z(t_n + s) \right| \dd s
    \leq \Dt \int_{t_n}^{t_{n+1}} \left| \pa_t^{\:2} z(t) \right| \dd t.
\end{equation}
En revanche cette approche n'exploite pas le caractère décroissant de $t
\mapsto z(t)$, et d'ailleurs cette dernière borne serait aussi valide
pour le schéma d'Euler explicite. Cette caractéristique peut être
exploitée en s'intéressant directement à la définition de~$\tau_n$. En
effet dans notre cas particulier, on a $z(t) = e^{-t/\eps} z_0$ donc 
\begin{equation*}
    \tau_n = \left(
        e^{-\Dt/\eps} - 1 + \frac{\Dt}{\eps}e^{-\Dt/\eps}
        \right) e^{-n \Dt/\eps} z_0 ,
\end{equation*}
ce qui peut se borner très grossièrement,
\begin{equation} \label{sec:intro:eq:euler_err2}
    |\tau_n| \leq e^{-n \Dt/\eps} |z_0|
\end{equation}
On remarque maintenant que l'erreur globale vérifie 
\begin{equation*}
    \left(1 + \frac{\Dt}{\eps}\right) \left( z_{n+1} - z(t_{n+1})\right)
    = z_n - z(t_n) - \tau_n 
\end{equation*}
d'où de proche en proche,
\begin{equation*}
    \left| z_{n+1} - z(t_{n+1}) \right| 
    \leq \sum_{k = 0}^n 
        \left(1 + \frac{\Dt}{\eps}\right)^{-k-1} |\tau_{n-k}| .
\end{equation*}
On applique brutalement une inégalité de Hölder sur la somme pour
obtenir finalement 
\begin{equation*}
    \left| z_{n+1} - z(t_{n+1}) \right| 
    \leq \left(1 + \frac{\Dt}{\eps}\right)^{-1} 
        \sum_{k = 0}^n |\tau_{k}| .
\end{equation*}
En exploitant~\eqref{sec:intro:eq:euler_err1}
et~\eqref{sec:intro:eq:euler_err2}, on obtient enfin 
\begin{equation*}
    \left| z_{n+1} - z(t_{n+1}) \right| 
    \leq \frac{\eps}{\eps + \Dt} \min\left( 
        \Dt \| \pa_t^{\:2} z \|_{L^1} ,
        \frac{ |z_0| }{ 1 - e^{-\Dt/\eps} } \right) .
\end{equation*}
Ici la norme $L^1$ est définie de manière canonique, c'est-à-dire $ \| u
\|_{L^1} \leq \int_0^T | u(t) | \dd t $. En l'occurrence, on connaît
exactement $z(t) = e^{-t/\eps} z_0$, donc on peut calculer $\|
\pa_t^{\:2} z \|_{L^1} = \frac{1}{\eps}(1 - e^{-T/\eps}) z_0$, ce qui
donne finalement pour tout $n$ entre $0$ et $N$, 
\begin{equation*}
    \left| z_n - z(t_n) \right| 
    \leq \frac{\Dt}{\eps + \Dt} |z_0| \min \left(
        1, \frac{\eps/\Dt}{1 - e^{-\Dt/\eps}}
    \right) .
\end{equation*}
Grâce au premier argument du $\min$, on est assuré que l'erreur est de
la forme $C\Dt$ pour tout $\Dt < \Dt_0$ avec $C$ et $\Dt_0$ des
constantes indépendantes de $\eps$. On remarque là une différence par
rapport au comportement du schéma explicite, qui demandait $\Dt \ll
\eps$. 
%
Le deuxième argument du $\min$ nous assure que l'erreur tend vers zéro
quand $\eps$ tend vers zéro. On dit que ce schéma est
L-stable,\todo{détails}

\todo[inline]{Tests avec Radau?}


Cependant, le coût de calcul à chaque pas du schéma est difficile à
connaître \textit{a priori}, puisqu'il y a un système de grande taille à
inverser. Ce coût augmente avec la dimension et la non-linéarité du
problème, et l'implémentation des méthodes demande un investissement
certain. En conséquence, ces méthodes sont disponibles en \enquote{boîte
noire} dans la boîte à outils de résolution d'équations différentielles
\texttt{solve\_ivp} de \texttt{scipy} en Python. Même pour les étudiants
en analyse numérique, la résolution de tels systèmes est rarement (voire
jamais) abordée. Il serait intéressant d'avoir accès à des méthodes tout
aussi performantes mais plus facilement abordables, quitte à perdre en
généralité. 





\subsection*{Méthodes de splitting}
\addcontentsline{toc}{subsection}{Méthodes de splitting}

Une autre approche courante est de séparer le problème en deux parties,
une raide et une non-raide. Pour la bonne étude de la méthode, on
écrit~\eqref{sec:intro:eq:pb_ztest} sous la
forme~\eqref{sec:intro:eq:u},~i.e. 
\begin{equation*}
    \pa_t u = -\frac{1}{\eps} A u + f(u)
\end{equation*}
avec $A = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}$ et $f(u) =
\begin{pmatrix} 1 \\ \cos(x) \end{pmatrix}$. Le
problème~\eqref{sec:intro:eq:pb_ztest} se sépare en
%
\begin{empheq}[left=\left\lbrace, right=\right.]{align*} &
    \pa_t u^{(1)} = -\frac{1}{\eps}A u^{(1)} ,
    \\ &
    \pa_t u^{(2)} = f(u^{(2)}) . \vphantom{\frac11}
\end{empheq}
%
On note $\varphi_t$, $\varphi^{(1)}_t$ et $\varphi^{(2)}_t$ les 
$t$-flots associés aux problèmes en $u$, $u^{(1)}$ et $u^{(2)}$ 
respectivement. On remarque qu'il est simple de calculer $\varphi^{(1)}$ de manière exacte, et simple de calculer $\varphi^{(2)}$ de manière 
numérique. Cependant, elles sont mélangées dans $\varphi$, ce qui rend 
le flot du problème d'origine difficile à calculer. Ainsi, on est en 
droit de se poser la question~: Est-il possible d'obtenir $\varphi$ à 
partir de $\varphi^{(1)}$ et de $\varphi^{(2)}$~?

La réponse à cette question est \enquote{partiellement}, et on appelle cette approche le \textit{splitting}. Le plus couramment utilisé est le splitting de Strang, qui s'écrit généralement
\begin{equation*}
    \varphi_t = \varphi^{(1)}_{t/2} \circ \varphi^{(2)}_{t} \circ \varphi^{(1)}_{t/2} + \bigO(t^3) .
\end{equation*}
Il est obtenu par symétrie à partir du splitting de Lie $\Phi_t = \varphi^{(1)}_{t} \circ \varphi^{(2)}_{t}$, qui a une erreur $\varphi_t = \Phi_t + \bigO(t^2)$. Attention, $\Phi_t$ n'est pas un $t$-flot au même sens que $\varphi_t$, c'est la solution particulière d'une EDO dans l'espace des morphismes. Dans le cas où $f$ est linéaire, on dispose de la formule de Baker-Campbell-Hausdorff (BCH),\todo{REF BCH}
\begin{equation*}
    \log \big( \Phi_t \big)
    = t\left(\frac{-1}{\eps}A + f\right) 
    - \frac{t^2}{2\eps} \left[A, f\right]
    + \frac{t^3}{12\eps^2}\big( [A,[A,f]] + \eps [f,[A,f]] \big)
    + \ldots
\end{equation*}
avec $[f,g] = fg - gf$ le commutateur de champs linéaires. Cette formule n'est valide que formellement, c'est-à-dire qu'elle ne converge pas forcément et que l'important est le terme général qui la génère. On peut la comparer à un développement de Taylor qu'on a poussé à un ordre \enquote{infini}. L'objet obtenu est une série entière en $t$, mais celle-ci peut avoir un rayon de convergence nul. Néanmoins, les termes de la série ont du sens et on peut en prendre les premiers termes pour construire des approximations, bien qu'il faille être prudent avec la régularité de la fonction pour obtenir des résultats rigoureux.

On remarque l'équivalence des proriétés suivantes~:
\begin{itemize}
    \item Le morphisme $\Phi_t$ est un flot;
    \item $\Phi_t$ et $\varphi_t$ coincïdent en tout $t$;
    \item Les champs $A$ et $f$ commutent.
\end{itemize}
Le morphisme $\Phi_t$ est un flot si et seulement si cette expression est linéaire en $t$, or ce n'est pas le cas en général. Le seul moyen que ce soit le cas est que $A$ et $f$ commutent. Ce résultat est aussi valide dans le cas non-linéaire, avec le commutateur
\begin{equation*}
    [f,g] = \pa_u f \cdot g - \pa_u g \cdot f 
\end{equation*}
qui définit une algèbre de Lie sur les champs de vecteurs. Ceci correspond à une manière plus géométrique de considérer les champs de vecteurs qui revient à les associer à l'opérateur de transport $\mathcal{D}_f(g) = \pa_u g \cdot f$. Ainsi, $[f,g] = \mathcal{D}_g(f) - \mathcal{D}_f(g)$. 

On définit l'erreur de splitting 
\begin{equation*}
    \err_{\mathrm{Lie}} 
    = \log \big( \Phi_t \big) - t\left(\frac{-1}{\eps}A + f\right) 
\end{equation*}
qui permet d'obtenir l'erreur de troncature du schéma par un passage à l'exponentielle. Il apparaît à partir de la formule de BCH que cette erreur est de taille $t^2/\eps$. 



\bigskip\bigskip\bigskip
En particulier, on dit le schéma préserve le comportement asymptotique, 
ce qui se traduit en \textit{asymptotic preserving} (AP) en anglais.
Cette notion reviendra dans la prochaine section. 



\bigskip\bigskip\bigskip
\textbf{Rq~:} On peut obtenir une approximation en tout point $t \in
[0,T]$ par interpolation. Le sujet de cette thèse n'est pas l'étude de
schémas numériques ou celle de méthodes d'interpolation, donc nous 
éviterons de fournir des détails superflus sur ces sujets. On évaluera
la qualité d'une approximation en fonction de la valeur aux points. 

Illustration rapide sur méthode d'Euler

Démonstration d'erreur en $\Dt/\eps$

Distinction entre convergence et stabilité



\subsection*{Méthodes générales pour systèmes raides}
\addcontentsline{toc}{subsection}{Méthodes générales pour systèmes raides}

Bouquin de Hairer, Lubich, Wanner

Présentation rapide de méthodes stiff (implicites)

Discussion du coût du pas de temps adaptatif

Splitting + simulations

Foreshadowing~: ordre des opérations pour AP et splitting exact pour
formes normales